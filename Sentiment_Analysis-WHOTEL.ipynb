{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis for Whispr\n",
    "\n",
    "1. import data from google sheets\n",
    "2. clean dataset and create synthetic variables\n",
    "3. summarize dataset: how many records per category, reviews over time\n",
    "4. evaluate sentiment of review, give confidence interval\n",
    "5. calculate summary insights: average sentiment / subjectivity per item, reviews per item\n",
    "6. compare against manual evaluation\n",
    "7. export data to google sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from textblob import TextBlob\n",
    "import gspread\n",
    "import pygsheets\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "from nltk import pos_tag_sents, pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet, stopwords, words\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_style('darkgrid')\n",
    "pd.options.display.max_rows = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a. Import data from GS using GSpread\n",
    "- connect to google sheets API\n",
    "- create spreadsheet and worksheet objects, explore GSpread library\n",
    "- create dataframe of reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 define the scope of your access tokens\n",
    "scope = ['https://www.googleapis.com/auth/drive','https://spreadsheets.google.com/feeds']\n",
    "\n",
    "#2 after getting oauth2 credentials in a json, obtain an access token from google authorization server\n",
    "#by creating serviceaccountcredentials and indicating scope, which controls resources / operations that an\n",
    "#access token permits\n",
    "creds = ServiceAccountCredentials.from_json_keyfile_name('client_secret.json', scope)\n",
    "\n",
    "#3 log into the google API using oauth2 credentials\n",
    "#returns gspread.Client instance\n",
    "c = gspread.authorize(creds)\n",
    "\n",
    "spreadsheet = c.open('UK Sentiment')\n",
    "worksheet = spreadsheet.worksheet('WHotel_Sentiment')\n",
    "records = worksheet.get_all_records()\n",
    "df = pd.DataFrame(records)\n",
    "df = df[['Contents','Sentiment','Topic','Location','Comment']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1b. Import data from GS using pygsheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_rating</th>\n",
       "      <th>Review</th>\n",
       "      <th>review_headline</th>\n",
       "      <th>Product (Taste/Experience)</th>\n",
       "      <th>Lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "      <td>I really like these bars, and so do the other ...</td>\n",
       "      <td>A very tasty and well-balanced treat</td>\n",
       "      <td>1</td>\n",
       "      <td>i really like these bar , and so do the other ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "      <td>I purchased these because I’m on the 16:8 IF d...</td>\n",
       "      <td>Great size snack for those of us wanting a hea...</td>\n",
       "      <td>1</td>\n",
       "      <td>i purchase these because i ’ m on the 16:8 if ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "      <td>These are great bars. I find when I'm training...</td>\n",
       "      <td>Price varies a lot !!!</td>\n",
       "      <td>1</td>\n",
       "      <td>these be great bar . i find when i 'm train an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "      <td>Not a protein bar but a very health-designed s...</td>\n",
       "      <td>Possibly the best tasting healthiest snack bar...</td>\n",
       "      <td>1</td>\n",
       "      <td>not a protein bar but a very health-designed s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "      <td>So good and actually quite low in sugar all co...</td>\n",
       "      <td>Definitely a bar to try and enjoy</td>\n",
       "      <td>1</td>\n",
       "      <td>so good and actually quite low in sugar all co...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        review_rating                                             Review  \\\n",
       "0  5.0 out of 5 stars  I really like these bars, and so do the other ...   \n",
       "1  5.0 out of 5 stars  I purchased these because I’m on the 16:8 IF d...   \n",
       "2  5.0 out of 5 stars  These are great bars. I find when I'm training...   \n",
       "3  5.0 out of 5 stars  Not a protein bar but a very health-designed s...   \n",
       "4  5.0 out of 5 stars  So good and actually quite low in sugar all co...   \n",
       "\n",
       "                                     review_headline  \\\n",
       "0               A very tasty and well-balanced treat   \n",
       "1  Great size snack for those of us wanting a hea...   \n",
       "2                             Price varies a lot !!!   \n",
       "3  Possibly the best tasting healthiest snack bar...   \n",
       "4                  Definitely a bar to try and enjoy   \n",
       "\n",
       "  Product (Taste/Experience)  \\\n",
       "0                          1   \n",
       "1                          1   \n",
       "2                          1   \n",
       "3                          1   \n",
       "4                          1   \n",
       "\n",
       "                                          Lemmatized  \n",
       "0  i really like these bar , and so do the other ...  \n",
       "1  i purchase these because i ’ m on the 16:8 if ...  \n",
       "2  these be great bar . i find when i 'm train an...  \n",
       "3  not a protein bar but a very health-designed s...  \n",
       "4  so good and actually quite low in sugar all co...  "
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#authorization in one step - read client_secret\n",
    "gc = pygsheets.authorize(service_file='client_secret.json')\n",
    "spreadsheet2 = gc.open('UK Sentiment')\n",
    "\n",
    "#clean up workbook \n",
    "for item in spreadsheet2.worksheets():\n",
    "    title = item.title\n",
    "    if item.title not in ['UK_Reviews','WHotel_Sentiment','WHOTELS_analyzed']:\n",
    "        worksheet2 = spreadsheet2.worksheet_by_title(str(item.title))\n",
    "        spreadsheet2.del_worksheet(worksheet2)\n",
    "        print('{} sheet deleted'.format(item.title))\n",
    "        \n",
    "worksheet2 = spreadsheet2.worksheet_by_title('WHotel_Sentiment')\n",
    "records2 = worksheet2.get_all_records()\n",
    "df2 = pd.DataFrame(records2)\n",
    "df2 = df2[['Contents','Sentiment','Topic','Location','Comment']]\n",
    "\n",
    "#get data for kind bars\n",
    "kindbar = spreadsheet.worksheet('UK_Reviews')\n",
    "kindrecords = kindbar.get_all_records()\n",
    "kind_df = pd.DataFrame(kindrecords)\n",
    "kind_df = kind_df[['review_rating','Review','review_headline','Product (Taste/Experience)']]\n",
    "\n",
    "kind_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Simple sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/christinejiang/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:16: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version. Use                 named aggregation instead.\n",
      "\n",
      "    >>> grouper.agg(name_1=func_1, name_2=func_2)\n",
      "\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sentiment_Category</th>\n",
       "      <th>Textblob_Score</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td rowspan=\"3\" valign=\"top\">Negative</td>\n",
       "      <td>Negative</td>\n",
       "      <td>-0.229419</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.003046</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Positive</td>\n",
       "      <td>0.379133</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.028125</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td rowspan=\"3\" valign=\"top\">Positive</td>\n",
       "      <td>Negative</td>\n",
       "      <td>-0.400000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.001145</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Positive</td>\n",
       "      <td>0.425419</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       mean  count\n",
       "Sentiment_Category Textblob_Score                 \n",
       "Negative           Negative       -0.229419   11.0\n",
       "                   Neutral         0.003046   72.0\n",
       "                   Positive        0.379133   55.0\n",
       "Neutral            Neutral         0.028125    1.0\n",
       "Positive           Negative       -0.400000    1.0\n",
       "                   Neutral         0.001145   14.0\n",
       "                   Positive        0.425419   20.0"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#baseline sentiment analysis - use textblob polarity, compare accuracy\n",
    "df['Sentiment_Category'] = df['Sentiment'].map({1: 'Positive',2:'Neutral',3:'Negative'})\n",
    "\n",
    "def pos_neg(polarity):\n",
    "    if polarity >= 0.1:\n",
    "        return 'Positive'\n",
    "    if polarity >= 0 and polarity < 0.1:\n",
    "        return 'Neutral'\n",
    "    else:\n",
    "        return 'Negative'\n",
    "\n",
    "df['Polarity'] = [TextBlob(x).polarity for x in df['Contents']]\n",
    "df['Subjectivity'] = [TextBlob(x).subjectivity for x in df['Contents']]\n",
    "df['Textblob_Score'] = df['Polarity'].apply(pos_neg)\n",
    "\n",
    "df.groupby(['Sentiment_Category','Textblob_Score'])['Polarity'].agg({'mean':np.mean, 'count':len})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. KNN Sentiment Analysis\n",
    "- data cleaning: remove hashtags and extra whitepsaces\n",
    "- lemmatize contents\n",
    "- count word frequencies of lemmatized words\n",
    "- calculate polarity and choose positive / negative words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'and then the night come\\u2063s \\u2063\\u2063 \\u2063\\u2063 \\u2063\\u2063 \\u2063\\u2063 \\u2063\\u2063 \\u2063\\u2063 \\u2063\\u2063 \\u2063\\u2063 \\u2063\\u2063 \\u2063\\u2063 \\u2063\\u2063 \\u2063\\u2063 \\u2063\\u2063 \\u2063\\u2063 \\u2063\\u2063 # bali # balitrio # seminyak # baliseminyak # islandofgod # seminyakbali # wbali # woobar # tanskin # beachtravellers # beachlover # beach # beachbabes # beach # beachvacay # beachlovers # beachwaves # bikini # bikinigirls # wanderlust # wandersoul # woundedsoul # asianhotties # eurasianhotties # eurasianbabes # eurasianhotties # indonesian # indonesia # indonesiangirl # asiangirls'"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lemmatize sentence\n",
    "#tokenize a sentence, tag it with its pos tags\n",
    "#for specific letters, convert to wn pos\n",
    "#lemmatize each word according to its pos\n",
    "#return a sentence of the lemmatized words\n",
    "#use this to convert each of the records in 'contents'\n",
    "#count the frequency of lemmatized words in contents\n",
    "#evaluate polarity\n",
    "#count frequency of top 10 lemmatized words in contents\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def nltk2wn(nltk_tag):\n",
    "    if nltk_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif nltk_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif nltk_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif nltk_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return None        \n",
    "    \n",
    "def lemmatize_sent(sentence):\n",
    "    nltk_tagged = pos_tag([x.lower() for x in nltk.word_tokenize(sentence)])\n",
    "    converted_tags = [(x[0], nltk2wn(x[1])) for x in nltk_tagged]\n",
    "    lemmatized_sent = []\n",
    "    for x in converted_tags:\n",
    "        if x[1] is None:\n",
    "            lemmatized_sent.append(x[0])\n",
    "        else:\n",
    "            lemmatized_sent.append(lemmatizer.lemmatize(x[0], pos = x[1]))                     \n",
    "    final_sentence = ' '.join(lemmatized_sent)\n",
    "    return final_sentence \n",
    "\n",
    "sentence = 'And then the night come⁣s ⁣⁣ ⁣⁣ ⁣⁣ ⁣⁣ ⁣⁣ ⁣⁣ ⁣⁣ ⁣⁣ ⁣⁣ ⁣⁣ ⁣⁣ ⁣⁣ ⁣⁣ ⁣⁣ ⁣⁣ #bali #balitrio #seminyak #baliseminyak #islandofgod #seminyakbali #wbali #woobar #tanskin #beachtravellers #beachlover #beach #beachbabes #beaches #beachvacay #beachlovers #beachwaves #bikini #bikinigirls #wanderlust #wandersoul #woundedsoul #asianhotties #eurasianhotties #eurasianbabes #eurasianhotties #indonesian #indonesia #indonesiangirl #asiangirls'\n",
    "lemmatize_sent(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words(df, lemmatized_col):\n",
    "    #create three checks: stopwords, punctuation, english\n",
    "    mystop = stopwords.words('english')\n",
    "    punctuation = string.punctuation\n",
    "    englishwords = [x.lower() for x in words.words()]\n",
    "\n",
    "    #lemmatize words in comments\n",
    "    allwords = TextBlob(str(df[lemmatized_col].values.tolist())).tokenize()\n",
    "\n",
    "    #create list of lemmatized words\n",
    "    finalwords = [word for word in allwords if word not in punctuation and word not in mystop and word in englishwords]\n",
    "\n",
    "    #for lemmatized words, create counts and polarity scores\n",
    "    counts = {x: finalwords.count(x) for x in finalwords}\n",
    "    word_df = pd.DataFrame(counts.items(), columns = ['word','count']).sort_values('count', ascending = False)\n",
    "    word_df['polarity'] = word_df['word'].apply(lambda x: TextBlob(x).polarity)\n",
    "    positives = word_df[word_df['polarity']>0].sort_values(['count','polarity'], ascending = False)\n",
    "    negatives = word_df[word_df['polarity']<0].sort_values(['count','polarity'], ascending = False)\n",
    "\n",
    "    toptenpos=positives.nlargest(20, columns='count')\n",
    "    toptenneg=negatives.nlargest(20, columns='count')\n",
    "    return toptenpos, toptenneg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "kind_df['Lemmatized'] = kind_df['Review'].apply(lemmatize_sent)\n",
    "kind_pos, kind_neg = count_words(kind_df, 'Lemmatized')\n",
    "\n",
    "df['Lemmatized'] = df['Contents'].apply(lemmatize_sent)\n",
    "whotels_pos, whotels_neg = count_words(df, 'Lemmatized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "      <th>polarity</th>\n",
       "      <th>weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>good</td>\n",
       "      <td>56</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>39.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>delicious</td>\n",
       "      <td>36</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>36.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>love</td>\n",
       "      <td>41</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>20.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>great</td>\n",
       "      <td>25</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>20.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>nice</td>\n",
       "      <td>22</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>13.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>best</td>\n",
       "      <td>12</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>healthy</td>\n",
       "      <td>24</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>12.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>kind</td>\n",
       "      <td>19</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>11.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>perfect</td>\n",
       "      <td>9</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>sweet</td>\n",
       "      <td>24</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>8.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>win</td>\n",
       "      <td>7</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>5.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>cheap</td>\n",
       "      <td>14</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>5.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>free</td>\n",
       "      <td>12</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>4.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>happy</td>\n",
       "      <td>6</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>4.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>really</td>\n",
       "      <td>18</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>3.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>much</td>\n",
       "      <td>17</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>3.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>lovely</td>\n",
       "      <td>6</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>full</td>\n",
       "      <td>8</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>2.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>quick</td>\n",
       "      <td>6</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>high</td>\n",
       "      <td>9</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>1.44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         word  count  polarity  weighted\n",
       "0        good     56  0.700000     39.20\n",
       "1   delicious     36  1.000000     36.00\n",
       "2        love     41  0.500000     20.50\n",
       "3       great     25  0.800000     20.00\n",
       "4        nice     22  0.600000     13.20\n",
       "5        best     12  1.000000     12.00\n",
       "6     healthy     24  0.500000     12.00\n",
       "7        kind     19  0.600000     11.40\n",
       "8     perfect      9  1.000000      9.00\n",
       "9       sweet     24  0.350000      8.40\n",
       "10        win      7  0.800000      5.60\n",
       "11      cheap     14  0.400000      5.60\n",
       "12       free     12  0.400000      4.80\n",
       "13      happy      6  0.800000      4.80\n",
       "14     really     18  0.200000      3.60\n",
       "15       much     17  0.200000      3.40\n",
       "16     lovely      6  0.500000      3.00\n",
       "17       full      8  0.350000      2.80\n",
       "18      quick      6  0.333333      2.00\n",
       "19       high      9  0.160000      1.44"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kind_pos['weighted'] = kind_pos['count']*kind_pos['polarity']\n",
    "kind_pos.sort_values('weighted', ascending = False).reset_index(drop=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
