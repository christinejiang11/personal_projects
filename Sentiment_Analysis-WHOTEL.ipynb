{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis for Whispr\n",
    "\n",
    "1. import data from google sheets\n",
    "2. clean dataset and create synthetic variables\n",
    "3. summarize dataset: how many records per category, reviews over time\n",
    "4. evaluate sentiment of review, give confidence interval\n",
    "5. calculate summary insights: average sentiment / subjectivity per item, reviews per item\n",
    "6. compare against manual evaluation\n",
    "7. export data to google sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from textblob import TextBlob\n",
    "import gspread\n",
    "import pygsheets\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "from nltk import pos_tag_sents, pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet, stopwords, words\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_style('darkgrid')\n",
    "pd.options.display.max_rows = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a. Import data from GS using GSpread\n",
    "- connect to google sheets API\n",
    "- create spreadsheet and worksheet objects, explore GSpread library\n",
    "- create dataframe of reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 define the scope of your access tokens\n",
    "scope = ['https://www.googleapis.com/auth/drive','https://spreadsheets.google.com/feeds']\n",
    "\n",
    "#2 after getting oauth2 credentials in a json, obtain an access token from google authorization server\n",
    "#by creating serviceaccountcredentials and indicating scope, which controls resources / operations that an\n",
    "#access token permits\n",
    "creds = ServiceAccountCredentials.from_json_keyfile_name('client_secret.json', scope)\n",
    "\n",
    "#3 log into the google API using oauth2 credentials\n",
    "#returns gspread.Client instance\n",
    "c = gspread.authorize(creds)\n",
    "\n",
    "spreadsheet = c.open('UK Sentiment')\n",
    "worksheet = spreadsheet.worksheet('WHotel_Sentiment')\n",
    "records = worksheet.get_all_records()\n",
    "df = pd.DataFrame(records)\n",
    "df = df[['Contents','Sentiment','Topic','Location','Comment']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1b. Import data from GS using pygsheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_rating</th>\n",
       "      <th>Review</th>\n",
       "      <th>review_headline</th>\n",
       "      <th>Product (Taste/Experience)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "      <td>I really like these bars, and so do the other ...</td>\n",
       "      <td>A very tasty and well-balanced treat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "      <td>I purchased these because I’m on the 16:8 IF d...</td>\n",
       "      <td>Great size snack for those of us wanting a hea...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "      <td>These are great bars. I find when I'm training...</td>\n",
       "      <td>Price varies a lot !!!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "      <td>Not a protein bar but a very health-designed s...</td>\n",
       "      <td>Possibly the best tasting healthiest snack bar...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "      <td>So good and actually quite low in sugar all co...</td>\n",
       "      <td>Definitely a bar to try and enjoy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        review_rating                                             Review  \\\n",
       "0  5.0 out of 5 stars  I really like these bars, and so do the other ...   \n",
       "1  5.0 out of 5 stars  I purchased these because I’m on the 16:8 IF d...   \n",
       "2  5.0 out of 5 stars  These are great bars. I find when I'm training...   \n",
       "3  5.0 out of 5 stars  Not a protein bar but a very health-designed s...   \n",
       "4  5.0 out of 5 stars  So good and actually quite low in sugar all co...   \n",
       "\n",
       "                                     review_headline  \\\n",
       "0               A very tasty and well-balanced treat   \n",
       "1  Great size snack for those of us wanting a hea...   \n",
       "2                             Price varies a lot !!!   \n",
       "3  Possibly the best tasting healthiest snack bar...   \n",
       "4                  Definitely a bar to try and enjoy   \n",
       "\n",
       "  Product (Taste/Experience)  \n",
       "0                          1  \n",
       "1                          1  \n",
       "2                          1  \n",
       "3                          1  \n",
       "4                          1  "
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#authorization in one step - read client_secret\n",
    "gc = pygsheets.authorize(service_file='client_secret.json')\n",
    "spreadsheet2 = gc.open('UK Sentiment')\n",
    "\n",
    "#clean up workbook \n",
    "for item in spreadsheet2.worksheets():\n",
    "    title = item.title\n",
    "    if item.title not in ['UK_Reviews','WHotel_Sentiment','WHOTELS_analyzed']:\n",
    "        worksheet2 = spreadsheet2.worksheet_by_title(str(item.title))\n",
    "        spreadsheet2.del_worksheet(worksheet2)\n",
    "        print('{} sheet deleted'.format(item.title))\n",
    "        \n",
    "worksheet2 = spreadsheet2.worksheet_by_title('WHotel_Sentiment')\n",
    "records2 = worksheet2.get_all_records()\n",
    "df2 = pd.DataFrame(records2)\n",
    "df2 = df2[['Contents','Sentiment','Topic','Location','Comment']]\n",
    "\n",
    "#get data for kind bars\n",
    "kindbar = spreadsheet.worksheet('UK_Reviews')\n",
    "kindrecords = kindbar.get_all_records()\n",
    "kind_df = pd.DataFrame(kindrecords)\n",
    "kind_df = kind_df[['review_rating','Review','review_headline','Product (Taste/Experience)']]\n",
    "\n",
    "kind_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Simple sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/christinejiang/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:16: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version. Use                 named aggregation instead.\n",
      "\n",
      "    >>> grouper.agg(name_1=func_1, name_2=func_2)\n",
      "\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sentiment_Category</th>\n",
       "      <th>Textblob_Score</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td rowspan=\"3\" valign=\"top\">Negative</td>\n",
       "      <td>Negative</td>\n",
       "      <td>-0.229419</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.003046</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Positive</td>\n",
       "      <td>0.379133</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.028125</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td rowspan=\"3\" valign=\"top\">Positive</td>\n",
       "      <td>Negative</td>\n",
       "      <td>-0.400000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.001145</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Positive</td>\n",
       "      <td>0.425419</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       mean  count\n",
       "Sentiment_Category Textblob_Score                 \n",
       "Negative           Negative       -0.229419   11.0\n",
       "                   Neutral         0.003046   72.0\n",
       "                   Positive        0.379133   55.0\n",
       "Neutral            Neutral         0.028125    1.0\n",
       "Positive           Negative       -0.400000    1.0\n",
       "                   Neutral         0.001145   14.0\n",
       "                   Positive        0.425419   20.0"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#baseline sentiment analysis - use textblob polarity, compare accuracy\n",
    "df['Sentiment_Category'] = df['Sentiment'].map({1: 'Positive',2:'Neutral',3:'Negative'})\n",
    "\n",
    "def pos_neg(polarity):\n",
    "    if polarity >= 0.1:\n",
    "        return 'Positive'\n",
    "    if polarity >= 0 and polarity < 0.1:\n",
    "        return 'Neutral'\n",
    "    else:\n",
    "        return 'Negative'\n",
    "\n",
    "df['Polarity'] = [TextBlob(x).polarity for x in df['Contents']]\n",
    "df['Subjectivity'] = [TextBlob(x).subjectivity for x in df['Contents']]\n",
    "df['Textblob_Score'] = df['Polarity'].apply(pos_neg)\n",
    "\n",
    "df.groupby(['Sentiment_Category','Textblob_Score'])['Polarity'].agg({'mean':np.mean, 'count':len})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. KNN Sentiment Analysis\n",
    "- data cleaning: remove hashtags and extra whitepsaces\n",
    "- lemmatize contents\n",
    "- count word frequencies of lemmatized words\n",
    "- calculate polarity and choose positive / negative words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'and then the night come\\u2063s \\u2063\\u2063 \\u2063\\u2063 \\u2063\\u2063 \\u2063\\u2063 \\u2063\\u2063 \\u2063\\u2063 \\u2063\\u2063 \\u2063\\u2063 \\u2063\\u2063 \\u2063\\u2063 \\u2063\\u2063 \\u2063\\u2063 \\u2063\\u2063 \\u2063\\u2063 \\u2063\\u2063 # bali # balitrio # seminyak # baliseminyak # islandofgod # seminyakbali # wbali # woobar # tanskin # beachtravellers # beachlover # beach # beachbabes # beach # beachvacay # beachlovers # beachwaves # bikini # bikinigirls # wanderlust # wandersoul # woundedsoul # asianhotties # eurasianhotties # eurasianbabes # eurasianhotties # indonesian # indonesia # indonesiangirl # asiangirls'"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lemmatize sentence\n",
    "#tokenize a sentence, tag it with its pos tags\n",
    "#for specific letters, convert to wn pos\n",
    "#lemmatize each word according to its pos\n",
    "#return a sentence of the lemmatized words\n",
    "#use this to convert each of the records in 'contents'\n",
    "#count the frequency of lemmatized words in contents\n",
    "#evaluate polarity\n",
    "#count frequency of top 10 lemmatized words in contents\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def nltk2wn(nltk_tag):\n",
    "    if nltk_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif nltk_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif nltk_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif nltk_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return None        \n",
    "    \n",
    "def lemmatize_sent(sentence):\n",
    "    nltk_tagged = pos_tag([x.lower() for x in nltk.word_tokenize(sentence)])\n",
    "    converted_tags = [(x[0], nltk2wn(x[1])) for x in nltk_tagged]\n",
    "    lemmatized_sent = []\n",
    "    for x in converted_tags:\n",
    "        if x[1] is None:\n",
    "            lemmatized_sent.append(x[0])\n",
    "        else:\n",
    "            lemmatized_sent.append(lemmatizer.lemmatize(x[0], pos = x[1]))                     \n",
    "    final_sentence = ' '.join(lemmatized_sent)\n",
    "    return final_sentence \n",
    "\n",
    "sentence = 'And then the night come⁣s ⁣⁣ ⁣⁣ ⁣⁣ ⁣⁣ ⁣⁣ ⁣⁣ ⁣⁣ ⁣⁣ ⁣⁣ ⁣⁣ ⁣⁣ ⁣⁣ ⁣⁣ ⁣⁣ ⁣⁣ #bali #balitrio #seminyak #baliseminyak #islandofgod #seminyakbali #wbali #woobar #tanskin #beachtravellers #beachlover #beach #beachbabes #beaches #beachvacay #beachlovers #beachwaves #bikini #bikinigirls #wanderlust #wandersoul #woundedsoul #asianhotties #eurasianhotties #eurasianbabes #eurasianhotties #indonesian #indonesia #indonesiangirl #asiangirls'\n",
    "lemmatize_sent(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words(df, lemmatized_col):\n",
    "    #create three checks: stopwords, punctuation, english\n",
    "    mystop = stopwords.words('english')\n",
    "    punctuation = string.punctuation\n",
    "    englishwords = [x.lower() for x in words.words()]\n",
    "\n",
    "    #lemmatize words in comments\n",
    "    allwords = TextBlob(str(df[lemmatized_col].values.tolist())).tokenize()\n",
    "\n",
    "    #create list of lemmatized words\n",
    "    finalwords = [word for word in allwords if word not in punctuation and word not in mystop and word in englishwords]\n",
    "\n",
    "    #for lemmatized words, create counts and polarity scores\n",
    "    counts = {x: finalwords.count(x) for x in finalwords}\n",
    "    word_df = pd.DataFrame(counts.items(), columns = ['word','count']).sort_values('count', ascending = False)\n",
    "    word_df['polarity'] = word_df['word'].apply(lambda x: TextBlob(x).polarity)\n",
    "    positives = word_df[word_df['polarity']>0].sort_values(['count','polarity'], ascending = False)\n",
    "    negatives = word_df[word_df['polarity']<0].sort_values(['count','polarity'], ascending = False)\n",
    "\n",
    "    toptenpos=positives.nlargest(10, columns='count').reset_index(drop=True)\n",
    "    toptenneg=negatives.nlargest(10, columns='count').reset_index(drop=True)\n",
    "    return toptenpos, toptenneg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "kind_df['Lemmatized'] = kind_df['Review'].apply(lemmatize_sent)\n",
    "kind_pos, kind_neg = count_words(kind_df, 'Lemmatized')\n",
    "\n",
    "df['Lemmatized'] = df['Contents'].apply(lemmatize_sent)\n",
    "whotels_pos, whotels_neg = count_words(df, 'Lemmatized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_dummies(df, review_col, pos_words, neg_words):\n",
    "    for word in pos_words.values:\n",
    "        newcol = 'pos_{}'.format(word[0])\n",
    "        df[newcol] = [1 if word[0] in x else 0 for x in df[review_col]]\n",
    "    for word in neg_words.values:\n",
    "        newcol = 'neg_{}'.format(word[0])\n",
    "        df[newcol] = [1 if word[0] in x else 0 for x in df[review_col]]\n",
    "    return df\n",
    "\n",
    "def pos_count(df):\n",
    "    columns = df.columns\n",
    "    df['pos_sum'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "whotels = pos_dummies(df, 'Contents', whotels_pos, whotels_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Contents</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>pos_love</th>\n",
       "      <th>pos_new</th>\n",
       "      <th>pos_live</th>\n",
       "      <th>pos_beautiful</th>\n",
       "      <th>pos_amazing</th>\n",
       "      <th>pos_fun</th>\n",
       "      <th>pos_first</th>\n",
       "      <th>...</th>\n",
       "      <th>neg_little</th>\n",
       "      <th>neg_parade</th>\n",
       "      <th>neg_past</th>\n",
       "      <th>neg_long</th>\n",
       "      <th>neg_limited</th>\n",
       "      <th>neg_wet</th>\n",
       "      <th>neg_drag</th>\n",
       "      <th>neg_pink</th>\n",
       "      <th>neg_sharp</th>\n",
       "      <th>neg_due</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>What I thought was the weirdest design choice ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.229401</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>New day, new sunset 🌅 #wkohsamui #beachlife #h...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.344156</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>#amsterdam #wamsterdam #finertravel #travelpho...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Best breakfast ever whotels at #whoteldubai 🤩 ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>#그립다😢 #bali #wbali #seminyak</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>169</td>\n",
       "      <td>...but really you can! 👙 Thank you to dukespir...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>#Goa #Wgoa #VagatorBeach #nature #photography ...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>171</td>\n",
       "      <td>Rule #01- Be healthy . . . #whotel #singapore ...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>172</td>\n",
       "      <td>Movida night #eventdinner #wbarcelonahotel #ba...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>173</td>\n",
       "      <td>Bliss Spa, W Hotel DC https://t.co/9jr01gmK1X</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>174 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Contents  Sentiment  Polarity  \\\n",
       "0    What I thought was the weirdest design choice ...          1  0.229401   \n",
       "1    New day, new sunset 🌅 #wkohsamui #beachlife #h...          1  0.344156   \n",
       "2    #amsterdam #wamsterdam #finertravel #travelpho...          1  0.000000   \n",
       "3    Best breakfast ever whotels at #whoteldubai 🤩 ...          1  0.766667   \n",
       "4                         #그립다😢 #bali #wbali #seminyak          1  0.000000   \n",
       "..                                                 ...        ...       ...   \n",
       "169  ...but really you can! 👙 Thank you to dukespir...          3  0.312500   \n",
       "170  #Goa #Wgoa #VagatorBeach #nature #photography ...          3  0.675000   \n",
       "171  Rule #01- Be healthy . . . #whotel #singapore ...          3  0.500000   \n",
       "172  Movida night #eventdinner #wbarcelonahotel #ba...          3  0.000000   \n",
       "173      Bliss Spa, W Hotel DC https://t.co/9jr01gmK1X          3  0.000000   \n",
       "\n",
       "     pos_love  pos_new  pos_live  pos_beautiful  pos_amazing  pos_fun  \\\n",
       "0           0        1         0              0            0        0   \n",
       "1           1        1         1              0            0        0   \n",
       "2           0        0         0              0            0        0   \n",
       "3           1        0         0              0            0        1   \n",
       "4           0        0         0              0            0        0   \n",
       "..        ...      ...       ...            ...          ...      ...   \n",
       "169         0        0         0              0            0        0   \n",
       "170         1        0         0              1            0        0   \n",
       "171         0        0         0              0            0        0   \n",
       "172         0        0         0              0            0        0   \n",
       "173         0        0         0              0            0        0   \n",
       "\n",
       "     pos_first  ...  neg_little  neg_parade  neg_past  neg_long  neg_limited  \\\n",
       "0            1  ...           1           0         0         0            0   \n",
       "1            0  ...           0           0         0         0            0   \n",
       "2            0  ...           0           0         0         0            0   \n",
       "3            0  ...           0           0         0         0            0   \n",
       "4            0  ...           0           0         0         0            0   \n",
       "..         ...  ...         ...         ...       ...       ...          ...   \n",
       "169          0  ...           0           0         0         0            0   \n",
       "170          0  ...           0           0         0         0            0   \n",
       "171          0  ...           0           0         0         0            0   \n",
       "172          0  ...           0           0         0         0            0   \n",
       "173          0  ...           0           0         0         0            0   \n",
       "\n",
       "     neg_wet  neg_drag  neg_pink  neg_sharp  neg_due  \n",
       "0          0         0         0          0        0  \n",
       "1          0         0         0          0        0  \n",
       "2          0         0         0          0        0  \n",
       "3          0         0         0          0        0  \n",
       "4          0         0         0          0        0  \n",
       "..       ...       ...       ...        ...      ...  \n",
       "169        0         0         0          0        0  \n",
       "170        0         0         0          0        0  \n",
       "171        0         0         0          0        0  \n",
       "172        0         0         0          0        0  \n",
       "173        0         0         0          0        0  \n",
       "\n",
       "[174 rows x 23 columns]"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_to_keep = [column for column in whotels.columns if column[:3] == 'pos' or column[:3] == 'neg']\n",
    "columns_to_keep\n",
    "\n",
    "final_columns = ['Contents','Sentiment','Polarity'] + columns_to_keep\n",
    "whotels[final_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
