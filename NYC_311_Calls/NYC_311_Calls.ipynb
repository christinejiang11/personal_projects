{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NYC 311 Calls Dashboard\n",
    "#### To Do:\n",
    "- multiprocessing/threading to get more data?\n",
    "- create cleaner categories; streamline google sheets pipeline?\n",
    "- bargraph: fix sizing, finalize categories\n",
    "- heatmap: more than one heatmap on a page?\n",
    "- geomap: finalize map type, fix slider"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup / Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from sodapy import Socrata\n",
    "import os\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import sys\n",
    "from fuzzywuzzy import process\n",
    "from fuzzywuzzy import fuzz\n",
    "import pygsheets\n",
    "from datetime import datetime, date, time \n",
    "import json\n",
    "\n",
    "from bokeh.plotting import figure, output_file, output_notebook, show, save, reset_output, gmap\n",
    "from bokeh.models import ColumnDataSource, GMapOptions, HoverTool, BasicTicker, ColorBar, LinearColorMapper, PrintfTickFormatter, Panel, Tabs, CheckboxButtonGroup, CheckboxGroup, RadioButtonGroup, TextInput, Slider, DateRangeSlider\n",
    "from bokeh.palettes import Spectral6, all_palettes, brewer\n",
    "from bokeh.transform import factor_cmap, transform, linear_cmap\n",
    "from bokeh.layouts import column, row, layout, WidgetBox\n",
    "from bokeh.io import output_file, show, curdoc\n",
    "from bokeh.sampledata.unemployment1948 import data\n",
    "from bokeh.application import Application\n",
    "from bokeh.application.handlers import FunctionHandler\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "pd.options.display.max_columns=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "753744\n"
     ]
    }
   ],
   "source": [
    "#define parameters for endpoint, dataset, and app token\n",
    "data_url = 'data.cityofnewyork.us'\n",
    "dataset = 'erm2-nwe9'\n",
    "app_token = 'dM7DDeidbAmgtydtJVV1epbiU'\n",
    "\n",
    "#sets up the connection, need application token to override throttling limits\n",
    "#username and password only required for creating or modifying data\n",
    "client = Socrata(data_url, app_token)\n",
    "client.timeout = 6000\n",
    "\n",
    "#count number of records in desired dataset\n",
    "record_count = client.get(dataset, select='count(*)', where=\"created_date >='2020-01-01'\")\n",
    "total_count = record_count[0]['count']\n",
    "print(total_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(chunk_size=100000, total_rows=int(total_count)):\n",
    "    start = 0\n",
    "    results=[]\n",
    "\n",
    "    #paginate through dataset in sets of 10000 to get all records since 2019\n",
    "    while True:\n",
    "        print(f'{start} rows retrieved')\n",
    "        results.extend(client.get(dataset,select=\"unique_key, created_date, closed_date, agency, agency_name, complaint_type, descriptor, location_type, incident_zip, borough, address_type, city, status, latitude, longitude, location\", where=\"created_date >= '2020-02-01'\", \n",
    "                                  limit=chunk_size, offset=start))\n",
    "        start += chunk_size\n",
    "        if start > total_rows:\n",
    "            break\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Only run if getting new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# orig_results = get_data()\n",
    "# orig_df = pd.DataFrame(orig_results)\n",
    "# path = '/Users/linyu/Documents/Python/data/'\n",
    "# orig_df.to_csv(path+'311_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def reduce_memory(df):\n",
    "#     \"\"\"improved version of memory reduction function. uses pd.to_numeric to downcast types;\n",
    "#     also considers whether there are few enough unique values to warrant use of category vs. object.\"\"\"\n",
    "#     orig_size = df.memory_usage().sum()/1024**2\n",
    "#     dtypes = df.dtypes.astype(str).unique()\n",
    "#     converted_float = pd.DataFrame()\n",
    "#     converted_int = pd.DataFrame()\n",
    "#     converted_obj = pd.DataFrame()\n",
    "#     converted_misc = pd.DataFrame()\n",
    "\n",
    "#     #convert floats\n",
    "#     selected_float = df.select_dtypes(include='float')\n",
    "#     converted_float = selected_float.apply(pd.to_numeric, downcast='float')\n",
    "#     float_size = selected_float.memory_usage().sum()/1024**2\n",
    "#     converted_float_size = converted_float.memory_usage().sum()/1024**2\n",
    "#     print(f'floats: {float_size:.2f} reduced to {converted_float_size:.2f} MB')\n",
    "\n",
    "#     #convert ints\n",
    "#     selected_int = df.select_dtypes(include='integer')\n",
    "#     converted_int = selected_int.apply(pd.to_numeric, downcast='integer')\n",
    "#     int_size = selected_int.memory_usage().sum()/1024**2\n",
    "#     converted_int_size = converted_int.memory_usage().sum()/1024**2\n",
    "#     print(f'ints: {int_size:.2f} reduced to {converted_int_size:.2f} MB')\n",
    "    \n",
    "#     #convert objects / categories\n",
    "#     selected_object = df.select_dtypes(include=['object', 'category'])\n",
    "#     obj_size = selected_object.memory_usage().sum()/1024**2\n",
    "#     for col in selected_object.columns:\n",
    "#         count = len(selected_object[col])\n",
    "#         unique = len(selected_object[col].astype(str).unique())\n",
    "#         if unique < count/2:\n",
    "#             converted_obj[col] = selected_object[col].astype(str).astype('category')\n",
    "#         else:\n",
    "#             converted_obj[col] = selected_object[col].astype(str)\n",
    "#     converted_obj_size = converted_obj.memory_usage().sum()/1024**2\n",
    "#     print(f'object: {obj_size:.2f} reduced to {converted_obj_size:.2f} MB')\n",
    "\n",
    "#     #join floats, ints, and objects / categories\n",
    "#     float_int = converted_float.join(converted_int)\n",
    "#     float_int_obj = float_int.join(converted_obj)\n",
    "    \n",
    "#     #for any columns of any other type, keep them the same and join to the converted dataframe\n",
    "#     no_change_cols = [x for x in df.columns if x not in float_int_obj.columns]\n",
    "#     reduced_df = float_int_obj.join(df[no_change_cols])\n",
    "    \n",
    "#     #re-order columns to appear in original order\n",
    "#     reduced_df = reduced_df[df.columns]\n",
    "#     reduced_size = reduced_df.memory_usage().sum()/1024**2\n",
    "#     print(f'final df: {orig_size:.2f} reduced to {reduced_size:.2f} MB, {(orig_size-reduced_size)/orig_size*100:.1f}% reduction')\n",
    "#     return reduced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to fix this - relative path\n",
    "user = 'christinejiang'\n",
    "path = '/Users/'+user+'/Documents/Python/data/'\n",
    "orig_df = pd.read_csv(path+'311_data.csv', usecols=['unique_key', 'created_date', 'closed_date', 'agency', 'agency_name',\n",
    "                                                 'complaint_type', 'descriptor', 'location_type', 'incident_zip', 'borough',\n",
    "                                                 'address_type', 'city', 'status', 'latitude', 'longitude', 'location'], parse_dates=['created_date', 'closed_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #display null values per column\n",
    "# plt.rc('figure',figsize=(15,4))\n",
    "# display(sns.heatmap(orig_df.isnull()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing\n",
    "- need to create a function that will show the new, unmapped categories for each new imported dataset\n",
    "- need to indicate column types upon reading in with pandas, use the reduce memory function after preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "##ingest all datetime as datetimes\n",
    "#leave strings as objects, integers as ints, floats as floats\n",
    "#specifically cast columns you want to change to diff dtype\n",
    "#use categorical if you're going to be grouping by (cardinality<1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    #look into vectorized functions\n",
    "    #note: .apply not vectorized, slow\n",
    "    df['created_mdy'] = df['created_date'].dt.date\n",
    "    df['created_year'] = df['created_date'].dt.year\n",
    "    df['created_month'] = df['created_date'].dt.month\n",
    "    df['created_day'] = df['created_date'].dt.day\n",
    "    df['created_weekday'] = df['created_date'].dt.day_name()\n",
    "    df['created_week'] = df['created_date'].dt.week\n",
    "    df['created_hour'] = df['created_date'].dt.hour\n",
    "    df['days_to_close'] = (df['closed_date'] - df['created_date']).dt.days\n",
    "    df['count'] = 1\n",
    "    df['hour'] = [x.strftime('%I %p') for x in df['created_date']]\n",
    "    \n",
    "    df['agency_name'] = df['agency_name'].astype('category')\n",
    "    df['complaint_type'] = df['complaint_type'].astype('category')\n",
    "    df['descriptor'] = df['descriptor'].astype('category')\n",
    "    df['location_type'] = df['location_type'].astype('category')\n",
    "    df['city'] = df['city'].astype('category')\n",
    "    df['borough'] = df['borough'].str.capitalize()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = preprocess(orig_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_col_values(workbook, df, columns):\n",
    "    \"\"\"for a list of columns, creates a new sheet for each column and exports unique values and their counts to that sheet\"\"\"\n",
    "    for col in columns:\n",
    "        value_counts = df[col].value_counts()\n",
    "        counts_df = pd.DataFrame(value_counts).reset_index()\n",
    "        #was getting an error with using fillna for categorical column, need to cast to string\n",
    "        counts_df['index'] = counts_df['index'].astype(str)\n",
    "        try:\n",
    "            worksheet = workbook.worksheet_by_title(col)\n",
    "        except Exception:\n",
    "            #ensure the error is in regards to missing the worksheet\n",
    "            print(sys.exc_info())\n",
    "            workbook.add_worksheet(col)\n",
    "            worksheet = workbook.worksheet_by_title(col)\n",
    "        worksheet.set_dataframe(counts_df, start='A1')\n",
    "    print(f'{len(columns)} sets of column values exported.')\n",
    "        \n",
    "def get_valid_names(workbook, columns, start='D1'):\n",
    "    \"\"\"extracts the valid names manually entered by the user in column D of the workbook\"\"\"\n",
    "    valid_names = {}\n",
    "    for col in columns:\n",
    "        worksheet = workbook.worksheet_by_title(col)\n",
    "        valid_matrix = worksheet.get_values(start='D1', end='D100')\n",
    "        valid_names[col] = [v[0] for v in valid_matrix]\n",
    "    return valid_names\n",
    "\n",
    "def fuzzy_match(value):\n",
    "    \"\"\"returns the best match for each column; fuzzy match score of < 90 will return 'Other'\"\"\"\n",
    "    match = process.extract(query=value, choices=valid_names[col], limit=1)\n",
    "    if match[0][1] < 90:\n",
    "        return 'Other'\n",
    "    else:\n",
    "        return match[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 sets of column values exported.\n"
     ]
    }
   ],
   "source": [
    "#use pygsheets to connect to workbook where we will export unique column values\n",
    "client = pygsheets.authorize(service_account_file=path+'client_secret.json')\n",
    "workbook = client.open('311_data_cleaning')\n",
    "columns = ['agency_name','complaint_type','descriptor','location_type','city']\n",
    "\n",
    "#export unique column values and their counts\n",
    "export_col_values(workbook, new_df, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get dictionary of lists with valid names for each column\n",
    "#change values in column D of each tab if you wish to change the possible output values\n",
    "valid_names = get_valid_names(workbook, columns, start='D1')\n",
    "\n",
    "#fuzzy match each of the columns to the available values\n",
    "for col in columns:\n",
    "    new_df['cleaned_'+col] = new_df[col].apply(fuzzy_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc_311_calls = new_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bokeh Visualizations\n",
    "- function to create bar graphs\n",
    "- function to create tables\n",
    "- function to create heatmaps\n",
    "- function to create geo map\n",
    "- function to create call outs\n",
    "- add visualizations and sliders to dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heatmap with Controls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatmap_tab(nyc_311_calls, x, y, value, title=None, x_ticks=None, y_ticks=None, exclude=None):\n",
    "    \n",
    "    def make_dataset(x, y, value, boroughs, start_date, end_date):\n",
    "        date_filter = nyc_311_calls[(nyc_311_calls['created_mdy'] >= start_date) & (nyc_311_calls['created_mdy'] <= end_date)]\n",
    "        borough_filter = date_filter[date_filter['borough'].isin(boroughs)]\n",
    "        pivot = borough_filter.pivot_table(values=value, index=x, columns=y, aggfunc='sum')\n",
    "        pivot.columns = pivot.columns.astype(str)\n",
    "        pivot.index = pivot.index.astype(str)\n",
    "        if exclude:\n",
    "            for exclusion in exclude:\n",
    "                try:\n",
    "                    pivot = pivot.drop(exclusion)\n",
    "                    print(f'{exclusion} dropped from index.')\n",
    "                except KeyError:\n",
    "                    print(f'{exclusion} dropped from columns.')\n",
    "                    pivot = pivot.drop(exclusion, axis=1)\n",
    "                except:\n",
    "                    print('Exclusion does not exist in index or columns.')\n",
    "        df_pivot = pd.DataFrame(pivot.stack()).reset_index()\n",
    "        df_pivot.columns = ['y','x','value']\n",
    "        return ColumnDataSource(df_pivot)\n",
    "    \n",
    "    def style(p):\n",
    "        p.title.align = 'center'\n",
    "        p.title.text_font_size = '17pt'\n",
    "        p.title.text_font = 'avenir'\n",
    "        p.title.text_color = 'lightgray'\n",
    "\n",
    "        p.axis.axis_label_text_font = 'avenir'\n",
    "        p.axis.axis_label_text_font_size = '12pt'\n",
    "        p.axis.axis_label_text_color = 'lightgray'\n",
    "        p.axis.major_label_text_font_size = '10pt'\n",
    "        p.axis.major_label_text_color = 'lightgray'\n",
    "        return p\n",
    "    \n",
    "    def make_plot(src):\n",
    "        colors = [\"#75968f\", \"#a5bab7\", \"#c9d9d3\", \"#e2e2e2\", \"#dfccce\", \"#ddb7b1\", \"#cc7878\", \"#933b41\", \"#550b1d\"]\n",
    "        mapper = LinearColorMapper(palette=colors, low=src.data['value'].min(), high=src.data['value'].max())\n",
    "        \n",
    "        if x_ticks:\n",
    "            x_range = x_ticks\n",
    "        else:\n",
    "            x_range = sorted(list(set(src.data['x'])))\n",
    "        \n",
    "        if y_ticks:\n",
    "            y_range = y_ticks\n",
    "        else:\n",
    "            y_range = sorted(list(set(src.data['y'])))\n",
    "        \n",
    "        p = figure(plot_width=900, plot_height=500, x_range=x_range, y_range=y_range, title=title)\n",
    "        p.rect(x='x', y='y', width=1, height=1, source=src, line_color='white', fill_color=transform('value', mapper))\n",
    "        color_bar = ColorBar(color_mapper=mapper, location=(0,0), ticker=BasicTicker(desired_num_ticks=len(colors)))\n",
    "        p.add_layout(color_bar, 'right')\n",
    "        hover = HoverTool(tooltips=[(x,'@x'),(y,'@y'), (value,'@value')])\n",
    "        p.add_tools(hover)\n",
    "        p.grid.visible=False\n",
    "        p = style(p)\n",
    "        return p\n",
    "    \n",
    "    def update(attr, old, new):\n",
    "        categories_to_plot = [categories_selection.labels[i] for i in categories_selection.active]\n",
    "        start_date = pd.Timestamp(float(date_range_slider.value[0])*1e6)\n",
    "        end_date = pd.Timestamp(float(date_range_slider.value[1])*1e6)\n",
    "        new_src = make_dataset(x, y, value, boroughs, start_date, end_date)\n",
    "        src.data.update(new_src.data)\n",
    "     \n",
    "    available_boroughs = list(set(nyc_311_calls['borough']))\n",
    "    available_boroughs.sort()\n",
    "    \n",
    "    #checkbox for neighborhoods\n",
    "    borough_selection = CheckboxGroup(labels=available_boroughs, active=[0,1,2,3,4], name='Boroughs')\n",
    "    borough_selection.on_change('active', update)\n",
    "    \n",
    "    #date range selection\n",
    "    date_range_slider = DateRangeSlider(title=\"Date Range: \", start=date(2020, 1, 1), end=date.today(), value=(date(2020, 1, 1), date.today()), \n",
    "                                        step=1, bar_color='lightslategray', tooltips=True)\n",
    "    date_range_slider.on_change('value',update)\n",
    "    \n",
    "    #set initial date params\n",
    "    initial_boroughs = [borough_selection.labels[i] for i in borough_selection.active]\n",
    "    start_date = pd.to_datetime(date_range_slider.value[0])\n",
    "    end_date = pd.to_datetime(date_range_slider.value[1])\n",
    "    \n",
    "    #make initial date\n",
    "    src = make_dataset(x, y, value, initial_boroughs, start_date, end_date)\n",
    "    plot = make_plot(src)\n",
    "    \n",
    "    controls=WidgetBox(date_range_slider, borough_selection)\n",
    "    layout = row(controls, plot)\n",
    "    tab = Panel(child=layout, title='Heatmap')\n",
    "    return tab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bar Graph with Controls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bargraph_tab(nyc_311_calls, categories=['cleaned_descriptor']):\n",
    "    \n",
    "    def make_dataset(category, value, num_categories):\n",
    "        grouped_df = pd.DataFrame(nyc_311_calls.groupby(category)[value].sum()).reset_index()\n",
    "        grouped_df[category] = grouped_df[category].astype(str)\n",
    "        grouped_df = grouped_df.sort_values(value, ascending = False)[:num_categories]\n",
    "        colors = ['#550b1d', '#933b41', '#cc7878', '#ddb7b1', '#dfccce', '#e2e2e2', '#c9d9d3', '#a5bab7', '#75968f']\n",
    "        try:\n",
    "            grouped_df['color'] = colors[:num_categories]\n",
    "        except KeyError:\n",
    "            print('Too many categories selected; select up to 9 categories to display')\n",
    "        return ColumnDataSource(grouped_df)\n",
    "        \n",
    "    def style(p):\n",
    "        p.xgrid.visible = False\n",
    "        p.ygrid.visible = False\n",
    "        p.toolbar.logo = None\n",
    "        p.toolbar_location = None        \n",
    "        return p\n",
    "    \n",
    "    def make_plot(src):\n",
    "        output_file = ('test.html')\n",
    "        p = figure(y_range = list(reversed(src.data[category])), plot_height=300, plot_width=600, \n",
    "                  x_axis_label='Calls')\n",
    "        \n",
    "#         mapper = LinearColorMapper(palette=colors, low=src.data['value'].min(), high=src.data['value'].max())\n",
    "        p.hbar(y=category, right=value, source=src, height=0.8, color='color', hover_color='white')\n",
    "        category_value = f'@{category}'\n",
    "        value_value = f'@{value}'\n",
    "        hover = HoverTool(tooltips=[(category, category_value), (value, value_value)])\n",
    "        p.add_tools(hover)\n",
    "        p = style(p)\n",
    "        return p\n",
    "        \n",
    "    def update():\n",
    "        pass\n",
    "    \n",
    "    value='count'\n",
    "    num_categories=8\n",
    "    \n",
    "    date_range_slider = DateRangeSlider(title=\"Date Range: \", start=date(2020, 1, 1), end=date.today(), value=(date(2020, 1, 1), date.today()), \n",
    "                                        step=1, bar_color='lightslategray', tooltips=True)\n",
    "    controls = WidgetBox(date_range_slider)\n",
    "\n",
    "    plots = {}\n",
    "    for i, category in enumerate(categories):\n",
    "        src = make_dataset(category, value, num_categories)\n",
    "        p = make_plot(src)\n",
    "        plots[i] = p\n",
    "    \n",
    "    row_1 = row(plots[2], plots[3])\n",
    "    row_2 = row(plots[0], plots[1])\n",
    "    layout = column(controls, row_1, row_2)\n",
    "    tab = Panel(child=layout, title='Bar Graph')\n",
    "    tabs = Tabs(tabs=[tab], background='#000000')\n",
    "    return tab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geomap with Controls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geomap_tab(nyc_311_calls):\n",
    "    path = '/Users/'+user+'/Documents/Python/data/'\n",
    "    map_path = '/Users/'+user+'/Documents/Python/personal_projects/NYC_311_Calls/'\n",
    "    with open(map_path+'map_style.txt') as json_file:\n",
    "        map_style_json = json.load(json_file)\n",
    "    map_style = json.dumps(map_style_json)\n",
    "    \n",
    "    def make_dataset(boroughs, display_num, start_date, end_date):\n",
    "        date_filter = nyc_311_calls[(nyc_311_calls['created_mdy'] >= start_date) & (nyc_311_calls['created_mdy'] <= end_date)]\n",
    "        borough_filter = date_filter[date_filter['borough'].isin(boroughs)]\n",
    "        borough_filter['lat_round'] = round(borough_filter['latitude'],3)\n",
    "        borough_filter['lon_round'] = round(borough_filter['longitude'],3)\n",
    "        latlon_df = pd.DataFrame(borough_filter.groupby(['lat_round', 'lon_round'])['count'].sum()).reset_index()\n",
    "        latlon_df['sizes'] = latlon_df['count']/latlon_df['count'].max()*70\n",
    "        latlon_sorted = latlon_df.sort_values('sizes', ascending=False)\n",
    "        latlon_display = latlon_sorted[:display_num]\n",
    "        return ColumnDataSource(latlon_display)\n",
    "    \n",
    "    def style(p):\n",
    "        p.title.align = 'center'\n",
    "        p.title.text_font_size = '17pt'\n",
    "        p.title.text_font = 'avenir'\n",
    "        p.title.text_color = 'dimgray'\n",
    "\n",
    "        p.xaxis.axis_label = 'Latitude'\n",
    "        p.yaxis.axis_label = 'Longitude'\n",
    "        p.axis.axis_label_text_font = 'avenir'\n",
    "        p.axis.axis_label_text_font_size = '12pt'\n",
    "        p.axis.axis_label_text_color = 'dimgray'\n",
    "        p.axis.major_label_text_font_size = '10pt'\n",
    "        p.axis.major_label_text_color = 'dimgray'\n",
    "        return p\n",
    "        \n",
    "    def make_plot(src):\n",
    "        with open(path+'client_secret.json') as f:\n",
    "            data = json.load(f)\n",
    "        api_key = data['google_api_key']\n",
    "        map_options = GMapOptions(lat=40.76, lng=-73.95, map_type='roadmap', zoom=11, styles=map_style)\n",
    "        call_map = gmap(api_key, map_options, title='311 Calls by Location', plot_width=700, plot_height=700)\n",
    "        call_map.circle(x='lon_round', y='lat_round', size='sizes', source=src, fill_alpha = 0.8, \n",
    "                        fill_color='salmon', line_color='firebrick')\n",
    "        \n",
    "        hover = HoverTool(tooltips=[('longitude','@lon_round'),('latitude','@lat_round'), ('count','@count')])\n",
    "        call_map.add_tools(hover)\n",
    "        call_map = style(call_map)\n",
    "        return call_map\n",
    "    \n",
    "    def update(attr, old, new):\n",
    "        boroughs_to_plot = [borough_selection.labels[i] for i in borough_selection.active]\n",
    "        top_n = int(display_labels[radio_button_group.active][4:])\n",
    "        start_date = pd.Timestamp(float(date_range_slider.value[0])*1e6)\n",
    "        end_date = pd.Timestamp(float(date_range_slider.value[1])*1e6)\n",
    "        new_src = make_dataset(boroughs_to_plot, top_n, start_date, end_date)\n",
    "        src.data.update(new_src.data)\n",
    "        \n",
    "    available_boroughs = list(set(nyc_311_calls['borough']))\n",
    "    available_boroughs.sort()\n",
    "    \n",
    "    #checkbox for neighborhoods\n",
    "    borough_selection = CheckboxGroup(labels=available_boroughs, active=[0,1,2,3,4], name='Boroughs')\n",
    "    borough_selection.on_change('active', update)\n",
    "    \n",
    "    #radio button for top N records to display\n",
    "    display_labels = ['Top 5', 'Top 100', 'Top 1000', 'Top 5000']\n",
    "    radio_button_group = RadioButtonGroup(labels=display_labels, active=3, name='Records to Display')\n",
    "    radio_button_group.on_change('active', update)\n",
    "    \n",
    "    #slider for date range\n",
    "    date_range_slider = DateRangeSlider(title=\"Date Range\", start=date(2020, 1, 1), end=date.today(), value=(date(2020, 1, 1), date(2020, 3, 1)), \n",
    "                                        step=1, bar_color='lightslategray', tooltips=True)\n",
    "    date_range_slider.on_change('value', update)\n",
    "    \n",
    "    #set initial dataset params\n",
    "    initial_boroughs = [borough_selection.labels[i] for i in borough_selection.active]\n",
    "    start_date = pd.to_datetime(date_range_slider.value[0])\n",
    "    end_date = pd.to_datetime(date_range_slider.value[1])\n",
    "    top_n = int(display_labels[radio_button_group.active][4:])\n",
    "    \n",
    "    #create initial plot\n",
    "    src = make_dataset(initial_boroughs, display_num=top_n, start_date=start_date, end_date=end_date)\n",
    "    p = make_plot(src)\n",
    "    controls = WidgetBox(date_range_slider, radio_button_group, borough_selection)\n",
    "    layout = row(controls, p)\n",
    "    tab = Panel(child=layout, title='Geomap')\n",
    "    tabs = Tabs(tabs=[tab], background='black')\n",
    "    return tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'categories_selection' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-254-4a88bb51f98d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m time_heatmap = heatmap_tab(nyc_311_calls, 'hour','created_weekday','count', 'Calls by Day and Hour', y_ticks=list(nyc_311_calls['hour'].unique())[::-1],\n\u001b[0;32m----> 4\u001b[0;31m                      x_ticks=['Sunday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday'])\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mcategory_heatmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mheatmap_tab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnyc_311_calls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cleaned_descriptor'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'created_week'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'count'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Calls by Complaint Type'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Other'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-251-73d7c4f86a0c>\u001b[0m in \u001b[0;36mheatmap_tab\u001b[0;34m(nyc_311_calls, x, y, value, title, x_ticks, y_ticks, exclude)\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0mplot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0mcontrols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mWidgetBox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdate_range_slider\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategories_selection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m     \u001b[0mlayout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontrols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mtab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPanel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Heatmap'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'categories_selection' is not defined"
     ]
    }
   ],
   "source": [
    "#time = ['11 PM', '10 PM', '09 PM', '08 PM', '07 PM', '06 PM', '05 PM', '04 PM', '03 PM', '02 PM', '01 PM', '12 PM', '11 AM', '10 AM', '09 AM', '08 AM', '07 AM', '06 AM', '05 AM', '04 AM', '03 AM', '02 AM', '01 AM', '12 AM']\n",
    "\n",
    "time_heatmap = heatmap_tab(nyc_311_calls, 'hour','created_weekday','count', 'Calls by Day and Hour', y_ticks=list(nyc_311_calls['hour'].unique())[::-1],\n",
    "                     x_ticks=['Sunday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday'])\n",
    "\n",
    "category_heatmap = heatmap_tab(nyc_311_calls, 'cleaned_descriptor','created_week','count', 'Calls by Complaint Type', exclude=['Other'])\n",
    "\n",
    "geomap = geomap_tab(nyc_311_calls)\n",
    "\n",
    "bargraph = bargraph_tab(nyc_311_calls, ['agency','cleaned_descriptor','cleaned_city', 'cleaned_location_type'])\n",
    "\n",
    "tabs = Tabs(tabs=[geomap, bargraph, time_heatmap, category_heatmap])\n",
    "output_file('dashboard.html')\n",
    "show(tabs)\n",
    "curdoc().theme = 'dark_minimal'\n",
    "curdoc().add_root(tabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##line graph\n",
    "# clean_processed['cleaned_descriptor'] = clean_processed['cleaned_descriptor'].astype(str)\n",
    "# clean_processed['created_mdy'] = clean_processed['created_mdy'].astype(str)\n",
    "# pivot = clean_processed.pivot_table(values='count', index='created_mdy', columns='cleaned_descriptor', aggfunc=sum).reset_index()\n",
    "# source = ColumnDataSource(pivot)\n",
    "\n",
    "# reset_output()\n",
    "# linegraph = figure(x_range=pivot['created_mdy'])\n",
    "# for col in pivot.columns:\n",
    "#     linegraph.line(x='created_mdy', y = col, source=source, color='red', legend='test')\n",
    "# factor_cmap(field_name='test', palette='Viridis256', factors=pivot.columns)\n",
    "\n",
    "# hover = HoverTool(tooltips=[(\"Date\",\"@created_mdy\"),(\"Ceiling\",\"@Ceiling\")])\n",
    "# linegraph.add_tools(hover)\n",
    "# show(linegraph)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
