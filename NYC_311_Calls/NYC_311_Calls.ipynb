{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NYC 311 Calls Dashboard\n",
    "#### To Do:\n",
    "- multiprocessing/threading to get more data?\n",
    "- create cleaner categories; streamline google sheets pipeline?\n",
    "- bargraph: fix sizing, finalize categories\n",
    "- heatmap: more than one heatmap on a page?\n",
    "- geomap: finalize map type, fix slider\n",
    "\n",
    "##### Questions:\n",
    "- best way to troubleshoot? was running server every time i made a new change, unable to trace where errors were coming from, would make edits and then spin up the entire server again\n",
    "- best way to split code into separate files? start out in separate files, or start out in one file?\n",
    "- have to convert strings to categories so that fuzzy match doesn't take forever, but then we cast these back to strings - is there a better way?\n",
    "- why does the server run things more than once before opening the dashboard?\n",
    "--------------------------------\n",
    "- cant have y axis dynamically update\n",
    "- legends choose arbitrary values\n",
    "- if nan occurs in any value, plots nothing\n",
    "- similar objects do not have similar arguments\n",
    "- documentation for every object is (args, kwargs)\n",
    "- weird things with jupyter lab?\n",
    "- can't access turbo color palette?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup / Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sodapy import Socrata\n",
    "import os\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from fuzzywuzzy import process, fuzz\n",
    "import pygsheets\n",
    "from datetime import datetime, date, time, timedelta \n",
    "import json\n",
    "import math \n",
    "import warnings\n",
    "import math\n",
    "warnings.simplefilter(\"ignore\")\n",
    "pd.options.display.max_columns=50\n",
    "\n",
    "from bokeh.plotting import figure, output_file, output_notebook, show, save, reset_output, gmap\n",
    "from bokeh.models import (ColumnDataSource, GMapOptions, HoverTool, ColorBar, LinearColorMapper, Panel, \n",
    "                                            Tabs, CheckboxButtonGroup, CheckboxGroup, RadioButtonGroup, TextInput, \n",
    "                                                  Slider, DateRangeSlider, NumeralTickFormatter, Dropdown, Div, Select, BasicTicker)\n",
    "from bokeh.palettes import brewer\n",
    "from bokeh.transform import factor_cmap, transform, linear_cmap\n",
    "from bokeh.layouts import column, row, layout, WidgetBox\n",
    "from bokeh.io import output_file, show, curdoc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "806819\n"
     ]
    }
   ],
   "source": [
    "#define parameters for endpoint, dataset, and app token\n",
    "data_url = 'data.cityofnewyork.us'\n",
    "dataset = 'erm2-nwe9'\n",
    "app_token = 'dM7DDeidbAmgtydtJVV1epbiU'\n",
    "\n",
    "#sets up the connection, need application token to override throttling limits\n",
    "#username and password only required for creating or modifying data\n",
    "client = Socrata(data_url, app_token)\n",
    "client.timeout = 6000\n",
    "\n",
    "#count number of records in desired dataset\n",
    "record_count = client.get(dataset, select='count(*)', where=\"created_date >='2020-01-01'\")\n",
    "total_count = record_count[0]['count']\n",
    "print(total_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(chunk_size=100000, total_rows=int(total_count)):\n",
    "    start = 0\n",
    "    results=[]\n",
    "\n",
    "    #paginate through dataset in sets of 10000 to get all records since start of 2020\n",
    "    while True:\n",
    "        print(f'{start} rows retrieved')\n",
    "        results.extend(client.get(dataset,select=\"unique_key, created_date, closed_date, agency, agency_name, complaint_type, descriptor, location_type, incident_zip, borough, address_type, city, status, latitude, longitude, location\", \n",
    "                                  where=\"created_date >= '2020-02-01'\", \n",
    "                                  limit=chunk_size, offset=start))\n",
    "        start += chunk_size\n",
    "        if start > total_rows:\n",
    "            break\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Only run if getting new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# orig_results = get_data()\n",
    "# orig_df = pd.DataFrame(orig_results)\n",
    "path ='../../data/'\n",
    "orig_df.to_csv(path+'311_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df shape: (639218, 15)\n",
      "df size: 73.15 MB\n"
     ]
    }
   ],
   "source": [
    "path ='../../data/'\n",
    "orig_df = pd.read_csv(path+'311_data.csv', \n",
    "                      usecols=['unique_key', 'created_date', 'closed_date', 'agency', 'agency_name',\n",
    "                            'complaint_type', 'descriptor', 'location_type', 'incident_zip', 'borough',\n",
    "                            'city', 'status', 'latitude', 'longitude', 'location'], \n",
    "                      parse_dates=['created_date', 'closed_date'])\n",
    "\n",
    "print(f'df shape: {orig_df.shape}')\n",
    "print(f'df size: {orig_df.memory_usage().sum()/1024**2:.2f} MB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #display null values per column\n",
    "# plt.rc('figure',figsize=(15,4))\n",
    "# sns.heatmap(orig_df.isnull())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    df['created_mdy'] = pd.to_datetime(df['created_date'].dt.date)\n",
    "    #df['created_year'] = df['created_date'].dt.year\n",
    "    #df['created_month'] = df['created_date'].dt.month\n",
    "    #df['created_day'] = df['created_date'].dt.day\n",
    "    df['created_weekday'] = df['created_date'].dt.day_name()\n",
    "    df['created_week'] = df['created_date'].dt.week\n",
    "    df['created_hour'] = df['created_date'].dt.hour\n",
    "    #df['days_to_close'] = (df['closed_date'] - df['created_date']).dt.days\n",
    "    df['hour'] = df['created_date'].dt.strftime('%I %p')\n",
    "    df['week_start'] = [x-timedelta(days=x.weekday()) for x in df['created_mdy']]\n",
    "    df['count'] = 1\n",
    "    \n",
    "    #have to convert to categorical so that fuzzy match doesn't take forever\n",
    "    #these get converted back to strings in order to plot\n",
    "    df['agency_name'] = df['agency_name'].astype('category')\n",
    "    df['complaint_type'] = df['complaint_type'].astype('category')\n",
    "    df['descriptor'] = df['descriptor'].astype('category')\n",
    "    df['location_type'] = df['location_type'].astype('category')\n",
    "    df['city'] = df['city'].astype('category')\n",
    "    df['borough'] = df['borough'].str.capitalize()\n",
    "    #can't covert NAN to int, so convert to string\n",
    "    df['incident_zip'] = df['incident_zip'].astype(str).str[0:5]\n",
    "    df['borough'] = df['borough'].replace('Staten island', 'Staten_Island')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc_311_calls = preprocess(orig_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_col_values(workbook, df, columns):\n",
    "    \"\"\"For a list of columns, creates a new sheet for each column in the Google Sheets workbook and exports each column's unique values and their corresponding value counts to that sheet.\n",
    "    Users can then use these value counts to determine the final clean categories for each column.\"\"\"\n",
    "    for col in columns:\n",
    "        value_counts = df[col].value_counts()\n",
    "        counts_df = pd.DataFrame(value_counts).reset_index()\n",
    "        #cast any categorical columns to strings\n",
    "        counts_df['index'] = counts_df['index'].astype(str)\n",
    "        #if the worksheet doesn't already exist for that column, add one\n",
    "        try:\n",
    "            worksheet = workbook.worksheet_by_title(col)\n",
    "        except Exception:\n",
    "            #ensure the error is in regards to missing the worksheet\n",
    "            print(sys.exc_info())\n",
    "            workbook.add_worksheet(col)\n",
    "            worksheet = workbook.worksheet_by_title(col)\n",
    "        worksheet.set_dataframe(counts_df, start='A1')\n",
    "        \n",
    "def get_valid_names(workbook, columns, start='D1'):\n",
    "    \"\"\"Extract the valid names manually entered by the user in column D in each sheet of the workbook.\"\"\"\n",
    "    valid_names = {}\n",
    "    for col in columns:\n",
    "        worksheet = workbook.worksheet_by_title(col)\n",
    "        valid_matrix = worksheet.get_values(start='D1', end='D100')\n",
    "        valid_names[col] = [v[0] for v in valid_matrix]\n",
    "    #return dictionary where keys are column names, and each value is a list of valid 'clean' categories\n",
    "    return valid_names\n",
    "\n",
    "def fuzzy_match(value):\n",
    "    \"\"\"Returns the best match for each column; fuzzy match score of < 90 will return 'Other'\"\"\"\n",
    "    match = process.extract(query=value, choices=valid_names[col], limit=1)\n",
    "    if match[0][1] < 90:\n",
    "        return 'Other'\n",
    "    else:\n",
    "        return match[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned columns created.\n"
     ]
    }
   ],
   "source": [
    "#use pygsheets to connect to data cleaning workbook\n",
    "client = pygsheets.authorize(service_account_file=path+'client_secret.json')\n",
    "workbook = client.open('311_data_cleaning')\n",
    "columns = ['agency_name','complaint_type','descriptor','location_type','city']\n",
    "\n",
    "#export unique column values and their counts\n",
    "export_col_values(workbook, nyc_311_calls, columns)\n",
    "\n",
    "#get dictionary of lists with valid names for each column\n",
    "#change values in column D of each tab if you wish to change the possible output values\n",
    "valid_names = get_valid_names(workbook, columns, start='D1')\n",
    "\n",
    "#fuzzy match each of the columns to the available values; create new 'cleaned' column \n",
    "for col in columns:\n",
    "    nyc_311_calls['cleaned_'+col] = nyc_311_calls[col].apply(fuzzy_match)\n",
    "\n",
    "print('Cleaned columns created.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Other                     326259\n",
       "Loud Music / Party         97549\n",
       "Social Distancing          47882\n",
       "Banging/Pounding           32075\n",
       "No Access                  19342\n",
       "Street Light Out           15138\n",
       "Blocked Hydrant            14709\n",
       "Pothole                    13458\n",
       "Parking Sign Violation     10515\n",
       "Noise                       7852\n",
       "Partial Access              6767\n",
       "Derelict Vehicles           6396\n",
       "Pests                       6077\n",
       "Wall / Ceiling              5364\n",
       "Leak                        5323\n",
       "Rat Sighting                4551\n",
       "Mold                        3111\n",
       "Graffiti                    2799\n",
       "Building / Apartment          12\n",
       "Name: cleaned_descriptor, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nyc_311_calls['cleaned_descriptor'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bokeh Visualizations\n",
    "- function to create bar graphs\n",
    "- function to create tables\n",
    "- function to create heatmaps\n",
    "- function to create geo map\n",
    "- function to create call outs\n",
    "- add visualizations and sliders to dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heatmap with Controls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# available_boroughs = list(set(nyc_311_calls['borough']))\n",
    "# date_filter = nyc_311_calls[(nyc_311_calls['created_mdy'] >= '2020-01-01') & (nyc_311_calls['created_mdy'] <= '2020-05-01')]\n",
    "# borough_filter = date_filter[date_filter['borough'].isin(available_boroughs)]\n",
    "# pivot = borough_filter.pivot_table(values='count', index='created_week', columns='cleaned_descriptor', aggfunc='sum')\n",
    "# pivot.columns = pivot.columns.astype(str)\n",
    "# pivot.index = pivot.index.astype(str)\n",
    "# df_pivot = pd.DataFrame(pivot.stack()).reset_index()\n",
    "# df_pivot.columns = ['x','y','value']\n",
    "# test=ColumnDataSource(df_pivot)\n",
    "# test.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatmap_tab(nyc_311_calls, x, y, title=None, x_ticks=None, y_ticks=None, x_label=None, y_label=None, exclude=None, tab_title='Heatmap'):\n",
    "    \n",
    "    #dataset for heatmap given x-category, y-category, boroughs, start date, and end date\n",
    "    #user can indicate a value to exclude in either the x-category or y-category\n",
    "    def make_dataset(x, y, boroughs, start_date, end_date):\n",
    "        date_filter = nyc_311_calls[(nyc_311_calls['created_mdy'] >= start_date) & (nyc_311_calls['created_mdy'] <= end_date)]\n",
    "        borough_filter = date_filter[date_filter['borough'].isin(boroughs)]\n",
    "        pivot = borough_filter.pivot_table(values='count', index=x, columns=y, aggfunc='sum')\n",
    "        pivot.columns = pivot.columns.astype(str)\n",
    "        pivot.index = pivot.index.astype(str)\n",
    "        if exclude:\n",
    "            for exclusion in exclude:\n",
    "                try:\n",
    "                    pivot = pivot.drop(exclusion)\n",
    "                except KeyError:\n",
    "                    pivot = pivot.drop(exclusion, axis=1)\n",
    "                except:\n",
    "                    print('Exclusion does not exist in index or columns.')\n",
    "        df_pivot = pd.DataFrame(pivot.stack()).reset_index()\n",
    "        df_pivot.columns = ['x','y','value']\n",
    "        return ColumnDataSource(df_pivot)\n",
    "    \n",
    "    def style(p):\n",
    "        p.title.align = 'center'\n",
    "        p.grid.visible=False\n",
    "        p.title.text_font_size = '19pt'\n",
    "        p.axis.axis_label_text_font_size = '12pt'\n",
    "        p.axis.major_label_text_font_size = '10pt'\n",
    "        \n",
    "        p.title.text_font = 'avenir'\n",
    "        p.axis.axis_label_text_font = 'avenir'\n",
    "        p.axis.major_label_text_font = 'avenir'\n",
    "        \n",
    "        p.title.text_color = 'dimgray'\n",
    "        p.axis.major_label_text_color = 'dimgray'\n",
    "        p.axis.axis_label_text_color = 'dimgray'\n",
    "        \n",
    "        p.xaxis.axis_label = x_label\n",
    "        p.yaxis.axis_label = y_label\n",
    "        p.xaxis.major_label_orientation = math.pi/4\n",
    "        \n",
    "        p.title.text_font_style = 'normal'\n",
    "        p.axis.axis_label_text_font_style = 'normal'\n",
    "        p.axis.major_label_text_font_style = 'normal'\n",
    "        p.xaxis.major_label_orientation = 'vertical'\n",
    "        return p\n",
    "    \n",
    "    def make_plot(src):\n",
    "        colors = [\"#4f685f\",'#64827c',\"#75968f\", \"#a5bab7\", \"#c9d9d3\", \"#e2e2e2\", \"#f9eed4\", \"#f9d1ac\", \"#ddb7b1\", \"#cc7878\", \"#a54c4c\",\"#933b41\", \"#550b1d\"]        \n",
    "        mapper = LinearColorMapper(palette='Magma256', low=src.data['value'].min(), high=src.data['value'].max())\n",
    "        \n",
    "        #user can indicate specific order for x or y ticks\n",
    "        if x_ticks:\n",
    "            x_range = x_ticks\n",
    "        else:\n",
    "            x_range = sorted(list(set(src.data['x'])))\n",
    "        \n",
    "        if y_ticks:\n",
    "            y_range = y_ticks\n",
    "        else:\n",
    "            y_range = sorted(list(set(src.data['y'])))\n",
    "        \n",
    "        p = figure(plot_width=1100, plot_height=700, x_range=x_range, y_range=y_range, title=title)\n",
    "        p.rect(x='x', y='y', width=1, height=1, source=src, line_color='white', fill_color=transform('value', mapper), fill_alpha=0.7)\n",
    "        color_bar = ColorBar(color_mapper=mapper, location=(0,0), ticker=BasicTicker(desired_num_ticks=len(colors)), scale_alpha=0.7)\n",
    "        p.add_layout(color_bar, 'right')\n",
    "        hover = HoverTool(tooltips=[(y,'@y'), (x,'@x'), ('Calls','@value{0,0}')])\n",
    "        p.add_tools(hover)\n",
    "        p = style(p)\n",
    "        return p\n",
    "    \n",
    "    def update(attr, old, new):\n",
    "        boroughs_to_plot = [borough_selection.labels[i] for i in borough_selection.active]\n",
    "        if isinstance(date_range_slider.value[0], (int, float)):\n",
    "            start_date = pd.Timestamp(float(date_range_slider.value[0])*1e6)\n",
    "            end_date = pd.Timestamp(float(date_range_slider.value[1])*1e6)\n",
    "        else:\n",
    "            start_date = pd.Timestamp(date_range_slider.value[0])\n",
    "            end_date = pd.Timestamp(date_range_slider.value[1])\n",
    "        new_src = make_dataset(x, y, boroughs_to_plot, start_date, end_date)\n",
    "        src.data.update(new_src.data)\n",
    "        print('plotting new stuff')\n",
    "        p.rect(x='x', y='y', width=1, height=1, source=src, line_color='white', fill_color=transform('value', mapper))\n",
    "        color_bar = ColorBar(color_mapper=mapper, location=(0,0), ticker=BasicTicker(desired_num_ticks=len(colors)))\n",
    "        p.add_layout(color_bar, 'right')\n",
    "        print('new stuff done')\n",
    "    \n",
    "    #set boroughs available for selection\n",
    "    available_boroughs = list(set(nyc_311_calls['borough']))\n",
    "    available_boroughs.sort()\n",
    "    \n",
    "    #checkbox for neighborhoods\n",
    "    borough_selection = CheckboxGroup(labels=available_boroughs, active=[0,1,2,3,4,5])\n",
    "    borough_selection.on_change('active', update)\n",
    "    \n",
    "    #date range selection\n",
    "    date_range_slider = DateRangeSlider(title=\"Date Range: \", start=date(2020, 1, 1), end=date.today(), value=(date(2020, 1, 1), date.today()), \n",
    "                                        step=1, bar_color='#a5bab7', tooltips=True)\n",
    "    date_range_slider.on_change('value',update)\n",
    "    \n",
    "    #set initial params\n",
    "    initial_boroughs = [borough_selection.labels[i] for i in borough_selection.active]\n",
    "    start_date = pd.to_datetime(date_range_slider.value[0])\n",
    "    end_date = pd.to_datetime(date_range_slider.value[1])\n",
    "    \n",
    "    #create initial plot\n",
    "    src = make_dataset(x, y, initial_boroughs, start_date, end_date)\n",
    "    plot = make_plot(src)\n",
    "    controls = WidgetBox(date_range_slider, borough_selection)\n",
    "    layout = row(controls, plot)\n",
    "    tab = Panel(child=layout, title=tab_title)\n",
    "    return tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # date_filter = nyc_311_calls[(nyc_311_calls['created_mdy'] >= '2020-01-01') & (nyc_311_calls['created_mdy'] <= '2020-05-01')]\n",
    "# # # borough_filter = date_filter[date_filter['borough'].isin(list(set(nyc_311_calls['borough'])))]\n",
    "# # # df = pd.DataFrame(borough_filter.groupby(['city', 'borough'])['count'].sum()).reset_index()\n",
    "# # # df_pivot = df.pivot_table(values='count', index='city', columns='borough')\n",
    "# # # df_pivot['sum'] = df_pivot.sum(axis=1)\n",
    "# # # df_sorted = df_pivot.sort_values('sum', ascending=False).fillna(0)[:16]\n",
    "# # # df_sorted.fillna(0)\n",
    "# # # test= ColumnDataSource(df_sorted)\n",
    "\n",
    "# # nyc_311_calls['borough'].replace('Staten island', 'Staten_Island').value_counts()\n",
    "# # boroughs=set(nyc_311_calls['borough'])\n",
    "# # [x for x in list(test.data.keys()) if x in boroughs]\n",
    "# # test.data['city'][::-1]\n",
    "\n",
    "\n",
    "# hover = HoverTool(tooltips=[\n",
    "#                         ('Brooklyn', '@Brooklyn'), \n",
    "#                         ('Bronx','@Bronx'), \n",
    "#                         ('Staten Island', '@Staten_Island'),\n",
    "#                         ('Manhattan', '@Manhattan'),\n",
    "#                         ('Queens', '@Queens'),\n",
    "#                         ('Unspecified','@Unspecified')])\n",
    "# hover.formatters = {\"@Brooklyn\": \"datetime\"}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bar Graph with Controls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bargraph_tab(nyc_311_calls):\n",
    "    \n",
    "    #dataset for bar graph given boroughs, categorical variable, start date, and end date\n",
    "    #only top 15 records are shown\n",
    "    def make_dataset(boroughs, category, start_date, end_date):\n",
    "        date_filter = nyc_311_calls[(nyc_311_calls['created_mdy'] >= start_date) & (nyc_311_calls['created_mdy'] <= end_date)]\n",
    "        borough_filter = date_filter[date_filter['borough'].isin(boroughs)]\n",
    "        df = pd.DataFrame(borough_filter.groupby([category, 'borough'])['count'].sum()).reset_index()\n",
    "        df_pivot = df.pivot_table(values='count', index=category, columns='borough')\n",
    "        df_pivot['sum'] = df_pivot.sum(axis=1)\n",
    "        df_sorted = df_pivot.sort_values('sum', ascending=False).fillna(0)[:15]\n",
    "        return ColumnDataSource(df_sorted)\n",
    "        \n",
    "    def style(p):\n",
    "        p.title.align = 'center'\n",
    "        p.title.text_font_size = '19pt'\n",
    "        p.axis.axis_label_text_font_size = '12pt'\n",
    "        p.axis.major_label_text_font_size = '10pt'\n",
    "        \n",
    "        p.title.text_font = 'avenir'\n",
    "        p.axis.axis_label_text_font = 'avenir'\n",
    "        p.axis.major_label_text_font = 'avenir'\n",
    "        p.legend.label_text_font = 'avenir'\n",
    "\n",
    "        p.title.text_color = 'dimgray'\n",
    "        p.axis.major_label_text_color = 'dimgray'\n",
    "        p.axis.axis_label_text_color = 'dimgray'\n",
    "        p.xaxis.axis_label = 'Calls'\n",
    "        \n",
    "        p.title.text_font_style = 'normal'\n",
    "        p.axis.axis_label_text_font_style = 'normal'\n",
    "        p.axis.major_label_text_font_style = 'normal'\n",
    "        p.legend.label_text_font_style = 'normal'\n",
    "        \n",
    "        p.toolbar_location = None\n",
    "        p.xaxis.formatter=NumeralTickFormatter(format=\"0,0\")\n",
    "        p.legend.location = \"bottom_right\"\n",
    "        return p\n",
    "    \n",
    "    #horizontal stacked bar graph: y-axis is unique category values, bars are split by boroughs\n",
    "    def make_plot(src, title):\n",
    "        active_category_values = list(reversed(src.data[active_category]))\n",
    "        boroughs = [x for x in list(src.data.keys()) if x in available_boroughs]\n",
    "        colors=brewer['YlGnBu'][len(boroughs)]\n",
    "        p = figure(y_range=active_category_values, title=title, plot_height=700, plot_width=1100)\n",
    "        p.hbar_stack(boroughs, y=active_category, height=0.9, source=src, color=colors, legend=[x.lower() for x in boroughs], fill_alpha=0.8)\n",
    "        category_value = f'@{active_category}'\n",
    "        #format number values in hover tool annotations as '10,000'\n",
    "        hover = HoverTool(tooltips=[(display_category, category_value),\n",
    "                                    ('Brooklyn', '@Brooklyn{0,0}'), \n",
    "                                    ('Bronx','@Bronx{0,0}'), \n",
    "                                    ('Staten Island', '@Staten_Island{0,0}'),\n",
    "                                    ('Manhattan', '@Manhattan{0,0}'),\n",
    "                                    ('Queens', '@Queens{0,0}'),\n",
    "                                    ('Unspecified','@Unspecified{0,0}')])\n",
    "        p.add_tools(hover)\n",
    "        p = style(p)\n",
    "        return p\n",
    "        \n",
    "    def update(attr, old, new):\n",
    "        #set new categorical variable, boroughs, and colors to plot\n",
    "        category_to_plot = labels_lookup[category_select.value]\n",
    "        boroughs_to_plot = [borough_selection.labels[i] for i in borough_selection.active]\n",
    "        colors=brewer['BuPu'][len(boroughs_to_plot)]\n",
    "        #convert date range slider values to timestamp, given dtype of returned value\n",
    "        if isinstance(date_range_slider.value[0], (int, float)):\n",
    "            start_date = pd.Timestamp(float(date_range_slider.value[0])*1e6)\n",
    "            end_date = pd.Timestamp(float(date_range_slider.value[1])*1e6)\n",
    "        else:\n",
    "            start_date = pd.Timestamp(date_range_slider.value[0])\n",
    "            end_date = pd.Timestamp(date_range_slider.value[1])\n",
    "        new_src = make_dataset(boroughs_to_plot, category_to_plot, start_date, end_date)\n",
    "        src.data.update(new_src.data)\n",
    "        \n",
    "        #this isn't working - trying to plot new y axis and x axis label given values chosen\n",
    "        category_to_plot_values = list(src.data[category_to_plot])\n",
    "        p = figure(y_range=category_to_plot_values, title=category_to_plot, plot_height=700, plot_width=1100)\n",
    "        p.hbar_stack(boroughs_to_plot, y=category_to_plot, height=0.9, source=src, color=colors, legend=[x.lower() for x in boroughs_to_plot])\n",
    "        p.xaxis.axis_label = category_to_plot \n",
    "        p.title.text = display_category\n",
    "        print(f'new category: {category_to_plot}, new boroughs: {boroughs_to_plot}, start: {start_date}, end: {end_date}')\n",
    "    \n",
    "    #set boroughs available for selection\n",
    "    available_boroughs = list(set(nyc_311_calls['borough']))\n",
    "    available_boroughs.sort()\n",
    "    \n",
    "    #checkbox for boroughs\n",
    "    borough_selection = CheckboxGroup(labels=available_boroughs, active=[0,1,2,3,4,5])\n",
    "    borough_selection.on_change('active', update)\n",
    "    \n",
    "    #slider for date range\n",
    "    date_range_slider = DateRangeSlider(title=\"Date Range: \", start=date(2020, 1, 1), end=date.today(), value=(date(2020, 1, 1), date.today()), \n",
    "                                        step=10, bar_color='#8c96c6', tooltips=True)\n",
    "    date_range_slider.on_change('value', update)\n",
    "    \n",
    "    #dropdown for which category to plot\n",
    "    display_labels = ['Agency', 'City', 'Descriptor', 'Location Type', 'Status', 'Zip Code']\n",
    "    actual_labels = ['agency_name', 'cleaned_city', 'cleaned_descriptor', 'cleaned_location_type', 'status', 'incident_zip']\n",
    "    labels_lookup = {display:actual for display, actual in zip(display_labels, actual_labels)}\n",
    "    category_select = Select(title=\"Category:\", value='Agency', options=display_labels)\n",
    "    category_select.on_change('value', update)\n",
    "    \n",
    "    #divider text for borough checkbox\n",
    "    div = Div(text=\"\"\"Borough:\"\"\", width=200, height=15)\n",
    "    \n",
    "    #set initial dataset params\n",
    "    display_category = category_select.value\n",
    "    active_category = labels_lookup[display_category]\n",
    "    initial_boroughs = [borough_selection.labels[i] for i in borough_selection.active]\n",
    "    start_date = pd.to_datetime(date_range_slider.value[0])\n",
    "    end_date = pd.to_datetime(date_range_slider.value[1])\n",
    "    \n",
    "    #create initial plot\n",
    "    src = make_dataset(initial_boroughs, active_category, start_date, end_date)\n",
    "    p = make_plot(src, f'Calls by {display_category}')\n",
    "    controls = WidgetBox(date_range_slider, category_select, div, borough_selection)\n",
    "    layout = row(controls, p)\n",
    "    tab = Panel(child=layout, title='Calls by Category')\n",
    "    tabs = Tabs(tabs=[tab])\n",
    "    return tab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geomap with Controls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geomap_tab(nyc_311_calls):\n",
    "    \n",
    "    #load json file with map style\n",
    "    #map styles to choose from: girly.txt, outspoken.txt, multibrand.txt\n",
    "    with open('multibrand.txt') as json_file:\n",
    "        map_style_json = json.load(json_file)\n",
    "    map_style = json.dumps(map_style_json)\n",
    "    \n",
    "    def make_dataset(boroughs, display_num, start_date, end_date):\n",
    "        #nyc_311_calls['created_mdy'] = pd.to_datetime(nyc_311_calls['created_mdy'])\n",
    "        date_filter = nyc_311_calls[(nyc_311_calls['created_mdy'] >= start_date) & (nyc_311_calls['created_mdy'] <= end_date)]\n",
    "        borough_filter = date_filter[date_filter['borough'].isin(boroughs)]\n",
    "        borough_filter['lat_round'] = round(borough_filter['latitude'],3)\n",
    "        borough_filter['lon_round'] = round(borough_filter['longitude'],3)\n",
    "        latlon_df = pd.DataFrame(borough_filter.groupby(['lat_round', 'lon_round'])['count'].sum()).reset_index()\n",
    "        latlon_df['sizes'] = latlon_df['count']/latlon_df['count'].max()*150\n",
    "        latlon_sorted = latlon_df.sort_values('sizes', ascending=False)\n",
    "        latlon_display = latlon_sorted[:display_num]\n",
    "        return ColumnDataSource(latlon_display)\n",
    "    \n",
    "    def style(p):\n",
    "        p.title.align = 'center'\n",
    "        p.title.text_font_size = '19pt'\n",
    "        p.axis.axis_label_text_font_size = '12pt'\n",
    "        p.axis.major_label_text_font_size = '10pt'\n",
    "        \n",
    "        p.title.text_font = 'avenir'\n",
    "        p.axis.axis_label_text_font = 'avenir'\n",
    "        p.axis.major_label_text_font = 'avenir'\n",
    "        \n",
    "        p.title.text_color = 'dimgray'\n",
    "        p.axis.major_label_text_color = 'dimgray'\n",
    "        p.axis.axis_label_text_color = 'dimgray'\n",
    "        \n",
    "        p.xaxis.axis_label = 'Latitude'\n",
    "        p.yaxis.axis_label = 'Longitude'\n",
    "        \n",
    "        p.title.text_font_style = 'normal'\n",
    "        p.axis.axis_label_text_font_style = 'normal'\n",
    "        p.axis.major_label_text_font_style = 'normal'\n",
    "        return p\n",
    "        \n",
    "    def make_plot(src):\n",
    "        with open(path+'client_secret.json') as f:\n",
    "            data = json.load(f)\n",
    "        api_key = data['google_api_key']\n",
    "        map_options = GMapOptions(lat=40.76, lng=-73.95, map_type='roadmap', zoom=12, styles=map_style)\n",
    "        call_map = gmap(api_key, map_options, title='311 Calls by Location', plot_width=850, plot_height=850)\n",
    "        call_map.circle(x='lon_round', y='lat_round', size='sizes', source=src, fill_alpha=0.8, \n",
    "                        fill_color='tomato', line_color='firebrick')\n",
    "        hover = HoverTool(tooltips=[('Longitude','@lon_round{0.0}'),\n",
    "                                    ('Latitude','@lat_round{0.0}'), \n",
    "                                    ('Calls','@count{0,0}')])\n",
    "        call_map.add_tools(hover)\n",
    "        call_map = style(call_map)\n",
    "        return call_map\n",
    "    \n",
    "    def update(attr, old, new):\n",
    "        boroughs_to_plot = [borough_selection.labels[i] for i in borough_selection.active]\n",
    "        top_n = int(display_labels[display_group.active][4:])\n",
    "        if isinstance(date_range_slider.value[0], (int, float)):\n",
    "        # pandas expects nanoseconds since epoch\n",
    "            start_date = pd.Timestamp(float(date_range_slider.value[0])*1e6)\n",
    "            end_date = pd.Timestamp(float(date_range_slider.value[1])*1e6)\n",
    "        else:\n",
    "            start_date = pd.Timestamp(date_range_slider.value[0])\n",
    "            end_date = pd.Timestamp(date_range_slider.value[1])\n",
    "        new_src = make_dataset(boroughs_to_plot, top_n, start_date, end_date)\n",
    "        src.data.update(new_src.data)\n",
    "    \n",
    "    #set boroughs available for selection\n",
    "    available_boroughs = list(set(nyc_311_calls['borough']))\n",
    "    available_boroughs.sort()\n",
    "    \n",
    "    #checkbox for neighborhoods\n",
    "    borough_selection = CheckboxGroup(labels=available_boroughs, active=[0,1,2,3,4])\n",
    "    borough_selection.on_change('active', update)\n",
    "    \n",
    "    #radio button for top N records to display\n",
    "    display_labels = ['Top 5', 'Top 100', 'Top 1000', 'Top 5000']\n",
    "    display_group = RadioButtonGroup(labels=display_labels, active=3)\n",
    "    display_group.on_change('active', update)\n",
    "    \n",
    "    #slider for date range\n",
    "    date_range_slider = DateRangeSlider(title=\"Date Range\", start=date(2020, 1, 1), end=date.today(), value=(date(2020, 1, 1), date.today()), \n",
    "                                        step=1, bar_color='goldenrod', tooltips=True)\n",
    "    date_range_slider.on_change('value', update)\n",
    "    \n",
    "    div1 = Div(text=\"\"\"Records to Display:\"\"\", width=200, height=15)\n",
    "    div2 = Div(text=\"\"\"Boroughs:\"\"\", width=200, height=15)\n",
    "    \n",
    "    #set initial dataset params\n",
    "    initial_boroughs = [borough_selection.labels[i] for i in borough_selection.active]\n",
    "    start_date = pd.to_datetime(date_range_slider.value[0])\n",
    "    end_date = pd.to_datetime(date_range_slider.value[1])\n",
    "    top_n = int(display_labels[display_group.active][4:])\n",
    "    \n",
    "    #create initial plot\n",
    "    src = make_dataset(initial_boroughs, top_n, start_date, end_date)\n",
    "    p = make_plot(src)\n",
    "    controls = WidgetBox(date_range_slider, div1, display_group, div2, borough_selection)\n",
    "    layout = row(controls, p)\n",
    "    tab = Panel(child=layout, title='Calls by Location')\n",
    "    return tab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linegraph with Controls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linegraph_tab(nyc_311_calls, x, y):\n",
    "    \n",
    "    def make_dataset(x, y, boroughs):\n",
    "        borough_filter = nyc_311_calls[nyc_311_calls['borough'].isin(boroughs)]\n",
    "        borough_filter[x] = borough_filter[x].astype(str)\n",
    "        borough_filter[y] = borough_filter[y].astype(str)\n",
    "        pivot = borough_filter.pivot_table(values='count', index=x, columns=y, aggfunc=sum).reset_index()\n",
    "        return ColumnDataSource(pivot)\n",
    "    \n",
    "#     def style(p):\n",
    "#         p.title.align = 'center'\n",
    "#         p.title.text_font_size = '19pt'\n",
    "#         p.axis.axis_label_text_font_size = '12pt'\n",
    "#         p.axis.major_label_text_font_size = '10pt'\n",
    "        \n",
    "#         p.title.text_font = 'avenir'\n",
    "#         p.axis.axis_label_text_font = 'avenir'\n",
    "#         p.axis.major_label_text_font = 'avenir'\n",
    "        \n",
    "#         p.title.text_color = 'dimgray'\n",
    "#         p.axis.major_label_text_color = 'dimgray'\n",
    "#         p.axis.axis_label_text_color = 'dimgray'\n",
    "        \n",
    "#         p.xaxis.axis_label = 'Latitude'\n",
    "#         p.yaxis.axis_label = 'Longitude'\n",
    "        \n",
    "#         p.title.text_font_style = 'normal'\n",
    "#         p.axis.axis_label_text_font_style = 'normal'\n",
    "#         p.axis.major_label_text_font_style = 'normal'\n",
    "#         p.xaxis.major_label_orientation = math.pi/4\n",
    "#         return p\n",
    "    \n",
    "    def make_plot(src):\n",
    "        p = figure(x_range=list(src.data[x]), title=f'311 Calls by {x} and {y}', plot_width=1000, plot_height=500)\n",
    "        for col in src.data.keys():\n",
    "            p.line(x=x, y=col, source=src, color='blue', legend=col)\n",
    "        #factor_cmap(field_name='test', palette='Viridis256', factors=pivot.columns)\n",
    "        date_value = f'@{x}'\n",
    "        type_value = f'@{y}'\n",
    "        hover = HoverTool(tooltips=[(\"Date\", date_value), ('Type', type_value)])\n",
    "        p.add_tools(hover)\n",
    "        #p = style(p)\n",
    "        return p\n",
    "    \n",
    "    def update(attr, old, new):\n",
    "        boroughs_to_plot = [borough_selection.labels[i] for i in borough_selection.active]\n",
    "        top_n = int(display_labels[radio_button_group.active][4:])\n",
    "        #start_date = pd.Timestamp(float(date_range_slider.value[0])*1e6)\n",
    "        #end_date = pd.Timestamp(float(date_range_slider.value[1])*1e6)\n",
    "        start_date = pd.to_datetime(float(date_range_slider.value[0])*1e6)\n",
    "        end_date = pd.to_datetime(float(date_range_slider.value[1])*1e6)\n",
    "        new_src = make_dataset(boroughs_to_plot, top_n, start_date, end_date)\n",
    "        src.data.update(new_src.data)\n",
    "    \n",
    "    available_boroughs = list(set(nyc_311_calls['borough']))\n",
    "    available_boroughs.sort()\n",
    "    \n",
    "    #checkbox for neighborhoods\n",
    "    borough_selection = CheckboxGroup(labels=available_boroughs, active=[0,1,2,3,4], name='Boroughs')\n",
    "    borough_selection.on_change('active', update)\n",
    "    \n",
    "    #slider for date range\n",
    "    date_range_slider = DateRangeSlider(title=\"Date Range\", start=date(2020, 1, 1), end=date.today(), value=(date(2020, 1, 1), date(2020, 3, 1)), \n",
    "                                        step=1, bar_color='lightslategray', tooltips=True)\n",
    "    date_range_slider.on_change('value', update)\n",
    "    \n",
    "    #set initial params\n",
    "    initial_boroughs = [borough_selection.labels[i] for i in borough_selection.active]\n",
    "    \n",
    "    #create initial plot\n",
    "    src = make_dataset(x, y, initial_boroughs)\n",
    "    p = make_plot(src)\n",
    "    controls = WidgetBox(date_range_slider, borough_selection)\n",
    "    layout = row(controls, p)\n",
    "    \n",
    "    tab = Panel(child=layout, title='Calls over Time')\n",
    "    return tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "Turbo256 = (\n",
    "    '#30123b', '#311542', '#32184a', '#341b51', '#351e58', '#36215f', '#372365', '#38266c', '#392972', '#3a2c79', '#3b2f7f', '#3c3285',\n",
    "    '#3c358b', '#3d3791', '#3e3a96', '#3f3d9c', '#4040a1', '#4043a6', '#4145ab', '#4148b0', '#424bb5', '#434eba', '#4350be', '#4353c2',\n",
    "    '#4456c7', '#4458cb', '#455bce', '#455ed2', '#4560d6', '#4563d9', '#4666dd', '#4668e0', '#466be3', '#466de6', '#4670e8', '#4673eb',\n",
    "    '#4675ed', '#4678f0', '#467af2', '#467df4', '#467ff6', '#4682f8', '#4584f9', '#4587fb', '#4589fc', '#448cfd', '#438efd', '#4291fe',\n",
    "    '#4193fe', '#4096fe', '#3f98fe', '#3e9bfe', '#3c9dfd', '#3ba0fc', '#39a2fc', '#38a5fb', '#36a8f9', '#34aaf8', '#33acf6', '#31aff5',\n",
    "    '#2fb1f3', '#2db4f1', '#2bb6ef', '#2ab9ed', '#28bbeb', '#26bde9', '#25c0e6', '#23c2e4', '#21c4e1', '#20c6df', '#1ec9dc', '#1dcbda',\n",
    "    '#1ccdd7', '#1bcfd4', '#1ad1d2', '#19d3cf', '#18d5cc', '#18d7ca', '#17d9c7', '#17dac4', '#17dcc2', '#17debf', '#18e0bd', '#18e1ba',\n",
    "    '#19e3b8', '#1ae4b6', '#1be5b4', '#1de7b1', '#1ee8af', '#20e9ac', '#22eba9', '#24eca6', '#27eda3', '#29eea0', '#2cef9d', '#2ff09a',\n",
    "    '#32f197', '#35f394', '#38f491', '#3bf48d', '#3ff58a', '#42f687', '#46f783', '#4af880', '#4df97c', '#51f979', '#55fa76', '#59fb72',\n",
    "    '#5dfb6f', '#61fc6c', '#65fc68', '#69fd65', '#6dfd62', '#71fd5f', '#74fe5c', '#78fe59', '#7cfe56', '#80fe53', '#84fe50', '#87fe4d',\n",
    "    '#8bfe4b', '#8efe48', '#92fe46', '#95fe44', '#98fe42', '#9bfd40', '#9efd3e', '#a1fc3d', '#a4fc3b', '#a6fb3a', '#a9fb39', '#acfa37',\n",
    "    '#aef937', '#b1f836', '#b3f835', '#b6f735', '#b9f534', '#bbf434', '#bef334', '#c0f233', '#c3f133', '#c5ef33', '#c8ee33', '#caed33',\n",
    "    '#cdeb34', '#cfea34', '#d1e834', '#d4e735', '#d6e535', '#d8e335', '#dae236', '#dde036', '#dfde36', '#e1dc37', '#e3da37', '#e5d838',\n",
    "    '#e7d738', '#e8d538', '#ead339', '#ecd139', '#edcf39', '#efcd39', '#f0cb3a', '#f2c83a', '#f3c63a', '#f4c43a', '#f6c23a', '#f7c039',\n",
    "    '#f8be39', '#f9bc39', '#f9ba38', '#fab737', '#fbb537', '#fbb336', '#fcb035', '#fcae34', '#fdab33', '#fda932', '#fda631', '#fda330',\n",
    "    '#fea12f', '#fe9e2e', '#fe9b2d', '#fe982c', '#fd952b', '#fd9229', '#fd8f28', '#fd8c27', '#fc8926', '#fc8624', '#fb8323', '#fb8022',\n",
    "    '#fa7d20', '#fa7a1f', '#f9771e', '#f8741c', '#f7711b', '#f76e1a', '#f66b18', '#f56817', '#f46516', '#f36315', '#f26014', '#f15d13',\n",
    "    '#ef5a11', '#ee5810', '#ed550f', '#ec520e', '#ea500d', '#e94d0d', '#e84b0c', '#e6490b', '#e5460a', '#e3440a', '#e24209', '#e04008',\n",
    "    '#de3e08', '#dd3c07', '#db3a07', '#d93806', '#d73606', '#d63405', '#d43205', '#d23005', '#d02f04', '#ce2d04', '#cb2b03', '#c92903',\n",
    "    '#c72803', '#c52602', '#c32402', '#c02302', '#be2102', '#bb1f01', '#b91e01', '#b61c01', '#b41b01', '#b11901', '#ae1801', '#ac1601',\n",
    "    '#a91501', '#a61401', '#a31201', '#a01101', '#9d1001', '#9a0e01', '#970d01', '#940c01', '#910b01', '#8e0a01', '#8b0901', '#870801',\n",
    "    '#840701', '#810602', '#7d0502', '#7a0402')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:bokeh.embed.util:\n",
      "You are generating standalone HTML/JS output, but trying to use real Python\n",
      "callbacks (i.e. with on_change or on_event). This combination cannot work.\n",
      "\n",
      "Only JavaScript callbacks may be used with standalone output. For more\n",
      "information on JavaScript callbacks with Bokeh, see:\n",
      "\n",
      "    http://bokeh.pydata.org/en/latest/docs/user_guide/interaction/callbacks.html\n",
      "\n",
      "Alternatively, to use real Python callbacks, a Bokeh server application may\n",
      "be used. For more information on building and running Bokeh applications, see:\n",
      "\n",
      "    http://bokeh.pydata.org/en/latest/docs/user_guide/server.html\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Models must be owned by only a single document, BasicTicker(id='6721', ...) is already in a doc",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-85-30d36a50ee6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtabs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mcurdoc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtheme\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'light_minimal'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mcurdoc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_root\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtabs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/bokeh/document/document.py\u001b[0m in \u001b[0;36madd_root\u001b[0;34m(self, model, setter)\u001b[0m\n\u001b[1;32m    302\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_roots\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pop_all_models_freeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trigger_on_change\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRootAddedEvent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msetter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/bokeh/document/document.py\u001b[0m in \u001b[0;36m_pop_all_models_freeze\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1017\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_all_models_freeze_count\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_all_models_freeze_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1019\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recompute_all_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1020\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recompute_all_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/bokeh/document/document.py\u001b[0m in \u001b[0;36m_recompute_all_models\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1040\u001b[0m             \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_detach_document\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mto_attach\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1042\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_attach_document\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1043\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_all_models\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecomputed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_all_models_by_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecomputed_by_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/bokeh/model.py\u001b[0m in \u001b[0;36m_attach_document\u001b[0;34m(self, doc)\u001b[0m\n\u001b[1;32m    712\u001b[0m         '''\n\u001b[1;32m    713\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_document\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_document\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 714\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Models must be owned by only a single document, %r is already in a doc\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    715\u001b[0m         \u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtheme\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_to_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_document\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Models must be owned by only a single document, BasicTicker(id='6721', ...) is already in a doc"
     ]
    }
   ],
   "source": [
    "time_heatmap = heatmap_tab(nyc_311_calls, 'created_weekday','hour','Calls by Day and Hour', \n",
    "                           x_ticks=['Sunday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday'],\n",
    "                           y_ticks=list(nyc_311_calls['hour'].unique())[::-1],\n",
    "                           x_label='Day of Week',\n",
    "                           y_label='Time of Day',\n",
    "                           tab_title='Calls by Day/Hour')\n",
    "\n",
    "category_heatmap = heatmap_tab(nyc_311_calls, 'week_start','cleaned_descriptor', 'Calls by Complaint Type', \n",
    "                               x_label='Week Start',\n",
    "                               y_label='Complaint',\n",
    "                               exclude=['Other'],\n",
    "                               tab_title='Calls by Type')\n",
    "\n",
    "geomap = geomap_tab(nyc_311_calls)\n",
    "\n",
    "bargraph = bargraph_tab(nyc_311_calls)\n",
    "\n",
    "linegraph1 = linegraph_tab(nyc_311_calls, 'created_mdy', 'cleaned_descriptor')\n",
    "\n",
    "tabs = Tabs(tabs=[geomap, bargraph, time_heatmap, category_heatmap, linegraph1])\n",
    "output_file('dashboard.html')\n",
    "show(tabs)\n",
    "curdoc().theme = 'light_minimal'\n",
    "curdoc().add_root(tabs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unused Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def reduce_memory(df):\n",
    "#     \"\"\"improved version of memory reduction function. uses pd.to_numeric to downcast types;\n",
    "#     also considers whether there are few enough unique values to warrant use of category vs. object.\"\"\"\n",
    "#     orig_size = df.memory_usage().sum()/1024**2\n",
    "#     dtypes = df.dtypes.astype(str).unique()\n",
    "#     converted_float = pd.DataFrame()\n",
    "#     converted_int = pd.DataFrame()\n",
    "#     converted_obj = pd.DataFrame()\n",
    "#     converted_misc = pd.DataFrame()\n",
    "\n",
    "#     #convert floats\n",
    "#     selected_float = df.select_dtypes(include='float')\n",
    "#     converted_float = selected_float.apply(pd.to_numeric, downcast='float')\n",
    "#     float_size = selected_float.memory_usage().sum()/1024**2\n",
    "#     converted_float_size = converted_float.memory_usage().sum()/1024**2\n",
    "#     print(f'floats: {float_size:.2f} reduced to {converted_float_size:.2f} MB')\n",
    "\n",
    "#     #convert ints\n",
    "#     selected_int = df.select_dtypes(include='integer')\n",
    "#     converted_int = selected_int.apply(pd.to_numeric, downcast='integer')\n",
    "#     int_size = selected_int.memory_usage().sum()/1024**2\n",
    "#     converted_int_size = converted_int.memory_usage().sum()/1024**2\n",
    "#     print(f'ints: {int_size:.2f} reduced to {converted_int_size:.2f} MB')\n",
    "    \n",
    "#     #convert objects / categories\n",
    "#     selected_object = df.select_dtypes(include=['object', 'category'])\n",
    "#     obj_size = selected_object.memory_usage().sum()/1024**2\n",
    "#     for col in selected_object.columns:\n",
    "#         count = len(selected_object[col])\n",
    "#         unique = len(selected_object[col].astype(str).unique())\n",
    "#         if unique < count/2:\n",
    "#             converted_obj[col] = selected_object[col].astype(str).astype('category')\n",
    "#         else:\n",
    "#             converted_obj[col] = selected_object[col].astype(str)\n",
    "#     converted_obj_size = converted_obj.memory_usage().sum()/1024**2\n",
    "#     print(f'object: {obj_size:.2f} reduced to {converted_obj_size:.2f} MB')\n",
    "\n",
    "#     #join floats, ints, and objects / categories\n",
    "#     float_int = converted_float.join(converted_int)\n",
    "#     float_int_obj = float_int.join(converted_obj)\n",
    "    \n",
    "#     #for any columns of any other type, keep them the same and join to the converted dataframe\n",
    "#     no_change_cols = [x for x in df.columns if x not in float_int_obj.columns]\n",
    "#     reduced_df = float_int_obj.join(df[no_change_cols])\n",
    "    \n",
    "#     #re-order columns to appear in original order\n",
    "#     reduced_df = reduced_df[df.columns]\n",
    "#     reduced_size = reduced_df.memory_usage().sum()/1024**2\n",
    "#     print(f'final df: {orig_size:.2f} reduced to {reduced_size:.2f} MB, {(orig_size-reduced_size)/orig_size*100:.1f}% reduction')\n",
    "#     return reduced_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
